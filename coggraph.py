# coggraph.py
import uuid
from CogUnit import CogUnit
import torch
import random
from env import GridEnvironment
import torch.nn.functional as F

MAX_CONNECTIONS = 4  # æ¯ä¸ªå•å…ƒæœ€å¤šè¿æ¥ 4 ä¸ªä¸‹æ¸¸


class TaskInjector:
    def __init__(self, target_position):
        self.target_position = target_position  # ç›®æ ‡åæ ‡ (x, y)

    def encode_goal(self, env_size):
        """å°†ç›®æ ‡ä½ç½®ç¼–ç æˆ one-hot å‘é‡ï¼ˆä¸è¾“å…¥åŒç»´åº¦ï¼‰"""
        index = self.target_position[1] * env_size + self.target_position[0]
        vec = torch.zeros(env_size * env_size)
        vec[index] = 1.0
        return vec

    def evaluate(self, env, emitter_outputs):
        """è¯„ä¼° emitter æ˜¯å¦â€œæŒ‡å‘â€ç›®æ ‡ä½ç½®"""
        if emitter_outputs is None:
            return False

        pred_index = torch.argmax(emitter_outputs.mean(dim=0)).item()
        x, y = pred_index % env.size, pred_index // env.size
        return (x, y) == self.target_position


class CogGraph:
    """
    CogGraph ç®¡ç†æ‰€æœ‰ CogUnit çš„é›†åˆå’Œè¿æ¥å…³ç³»ï¼š
    - æ·»åŠ  / åˆ é™¤å•å…ƒ
    - ç®¡ç†è¿æ¥ï¼ˆå¯æ‹“å±•ä¸ºå›¾ï¼‰
    - è°ƒåº¦æ¯ä¸€è½®æ‰€æœ‰ CogUnit çš„æ›´æ–°ã€åˆ†è£‚ã€æ­»äº¡ï¼Œå¹¶ä¼ é€’è¾“å‡º
    """
    def __init__(self):
        self.env_size = 5  # åˆå§‹ç¯å¢ƒ 5x5
        self.env = GridEnvironment(size=self.env_size)  # åˆ›å»ºç¯å¢ƒ
        self.task = TaskInjector(target_position=(self.env_size - 1, self.env_size - 1))  # åˆå§‹ç›®æ ‡ç‚¹
        self.target_vector = self.task.encode_goal(self.env_size)  # åˆå§‹ç›®æ ‡å‘é‡
        self.max_total_energy = 200  # åˆå§‹æœ€å¤§æ€»èƒ½é‡
        self.target_vector = torch.ones(50)
        self.connection_usage = {}  # {(from_id, to_id): last_used_step}
        self.current_step = 0
        self.units = []
        self.connections = {}  # {from_id: {to_id: strength_float}}
        self.unit_map = {}     # {unit_id: CogUnit å®ä¾‹} å¿«é€Ÿç´¢å¼•å•å…ƒ

    def add_unit(self, unit: CogUnit):
        # å°†å•å…ƒåŠ å…¥å›¾ç»“æ„ä¸­
        self.units.append(unit)
        self.unit_map[unit.id] = unit
        self.connections[unit.id] = {}

    def remove_unit(self, unit: CogUnit):
        # ä»å›¾ä¸­ç§»é™¤å•å…ƒåŠå…¶è¿æ¥
        self.units = [u for u in self.units if u.id != unit.id]
        if unit.id in self.connections:
            del self.connections[unit.id]
        if unit.id in self.unit_map:
            del self.unit_map[unit.id]
        for k in self.connections:
            if unit.id in self.connections[k]:
                del self.connections[k][unit.id]

    def connect(self, from_unit: CogUnit, to_unit: CogUnit):
        if from_unit.id not in self.connections:
            self.connections[from_unit.id] = {}  # to_id â†’ strength

        if to_unit.id in self.connections[from_unit.id]:
            return

        # è¶…è¿‡ä¸Šé™æ—¶ï¼Œç§»é™¤ strength æœ€å¼±çš„è¿æ¥
        if len(self.connections[from_unit.id]) >= MAX_CONNECTIONS:
            weakest_id = min(
                self.connections[from_unit.id],
                key=lambda uid: self.connections[from_unit.id][uid]
            )
            del self.connections[from_unit.id][weakest_id]
            print(f"[è¿æ¥æ›¿æ¢] {from_unit.id} ç§»é™¤æœ€å¼±è¿æ¥ {weakest_id}")

        # å»ºç«‹æ–°è¿æ¥ï¼Œåˆå§‹æƒé‡ä¸º 1.0
        self.connections[from_unit.id][to_unit.id] = 1.0
        strength = self.connections[from_unit.id][to_unit.id]
        print(f"[è¿æ¥å»ºç«‹] {from_unit.id} â†’ {to_unit.id} (strength={strength:.2f})")

    def total_energy(self):
        return sum(unit.energy for unit in self.units)

    def merge_redundant_units(self):
        merged_pairs = set()
        new_units = []

        for i, u1 in enumerate(self.units):
            for j in range(i + 1, len(self.units)):
                u2 = self.units[j]

                # è·³è¿‡å·²æ ‡è®°
                if u1.id in merged_pairs or u2.id in merged_pairs:
                    continue

                # å¿…é¡»æ˜¯ processor æˆ– emitter
                if u1.get_role() != u2.get_role():
                    continue

                # è·ç¦»åˆ¤æ–­
                def euclidean(p1, p2):
                    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5

                dist = euclidean(u1.get_position(), u2.get_position())
                if dist > 3.0:
                    continue

                # è¾“å‡ºç›¸ä¼¼åº¦åˆ¤æ–­ï¼ˆcosine similarityï¼‰
                # === è¾“å‡ºç›¸ä¼¼åº¦åˆ¤æ–­ï¼ˆcosine similarityï¼‰===
                output1 = u1.get_output().squeeze(0)
                output2 = u2.get_output().squeeze(0)

                # ğŸ”¥ è‡ªåŠ¨è¡¥é›¶åˆ°å½“å‰ç¯å¢ƒé¢„æœŸå°ºå¯¸
                target_dim = max(output1.shape[0], output2.shape[0])

                if output1.shape[0] < target_dim:
                    padding = (0, target_dim - output1.shape[0])
                    output1 = torch.nn.functional.pad(output1, padding, value=0)

                if output2.shape[0] < target_dim:
                    padding = (0, target_dim - output2.shape[0])
                    output2 = torch.nn.functional.pad(output2, padding, value=0)

                sim = F.cosine_similarity(output1, output2, dim=0).item()

                if sim < 0.95:
                    continue

                # âœ… æ»¡è¶³æ¡ä»¶ï¼Œæ‰§è¡Œåˆå¹¶
                print(f"[åˆå¹¶è§¦å‘] {u1.id} å’Œ {u2.id} åˆå¹¶ä¸ºæ–°å•å…ƒ")

                merged = CogUnit(role=u1.get_role())
                merged.position = (
                    (u1.get_position()[0] + u2.get_position()[0]) // 2,
                    (u1.get_position()[1] + u2.get_position()[1]) // 2
                )
                merged.state = (u1.state + u2.state) / 2
                merged.age = int((u1.age + u2.age) / 2)
                merged.energy = u1.energy + u2.energy + 0.1  # å¥–åŠ±åˆå¹¶èƒ½é‡
                merged.last_output = (u1.last_output + u2.last_output) / 2

                # åŠ å…¥æ–°å•å…ƒ
                new_units.append(merged)
                merged_pairs.update({u1.id, u2.id})

                # é‡å®šå‘è¿æ¥ï¼š
                for from_id, to_dict in self.connections.items():
                    if u1.id in to_dict or u2.id in to_dict:
                        if from_id in self.unit_map:  # é˜²æ­¢ä¸Šæ¸¸å·²ç»è¢«åˆå¹¶åˆ é™¤
                            self.connect(self.unit_map[from_id], merged)

                for to_id in self.connections.get(u1.id, {}):
                    if to_id in self.unit_map:  # âœ… é˜²æ­¢è¿æ¥åˆ°å·²è¢«åˆ é™¤çš„å•å…ƒ
                        self.connect(merged, self.unit_map[to_id])
                        print(f"[è¿æ¥é‡å®šå‘] {merged.id} â†’ {to_id}ï¼ˆç»§æ‰¿è‡ª {u1.id}ï¼‰")

                for to_id in self.connections.get(u2.id, {}):
                    if to_id in self.unit_map:
                        self.connect(merged, self.unit_map[to_id])
                        print(f"[è¿æ¥é‡å®šå‘] {merged.id} â†’ {to_id}ï¼ˆç»§æ‰¿è‡ª {u2.id}ï¼‰")

        # æ‰§è¡Œåˆ é™¤ & æ·»åŠ 
        for uid in merged_pairs:
            if uid in self.unit_map:
                print(f"[åˆå¹¶åˆ é™¤] {uid}")
                self.remove_unit(self.unit_map[uid])

        for u in new_units:
            self.add_unit(u)

    def restructure_common_subgraphs(self):
        """
        æ£€æŸ¥å¹¶é‡æ„é«˜åº¦å…±ç°ã€è¾“å‡ºç›¸ä¼¼çš„ processor â†’ emitter å­å›¾ç»“æ„ã€‚
        å°†å®ƒä»¬åˆå¹¶ä¸ºä¸€ä¸ªæ–°å­å›¾ï¼šnew_processor â†’ new_emitter
        """
        candidates = []

        # éå†æ‰€æœ‰ processor â†’ emitter è¿æ¥
        for u1 in self.units:
            if u1.get_role() != "processor":
                continue
            for eid in self.connections.get(u1.id, {}):
                if eid not in self.unit_map:
                    continue
                u2 = self.unit_map[eid]
                if u2.get_role() != "emitter":
                    continue
                candidates.append((u1, u2))

        # æ£€æŸ¥æ¯å¯¹å­å›¾æ˜¯å¦æ»¡è¶³å…±ç°ä¸è¾“å‡ºç›¸ä¼¼
        for i in range(len(candidates)):
            for j in range(i + 1, len(candidates)):
                p1, e1 = candidates[i]
                p2, e2 = candidates[j]

                if p1.id == p2.id or e1.id == e2.id:
                    continue

                # 1. æ£€æŸ¥å…±ç°ï¼ˆæœ€è¿‘ 5 æ­¥è°ƒç”¨é¢‘ç‡éƒ½ä¸ä¸º 0ï¼‰
                if min(p1.call_history[-3:], default=0) == 0 or min(p2.call_history[-3:], default=0) == 0:
                    continue

                # 2. æ£€æŸ¥è¾“å‡ºç›¸ä¼¼æ€§
                import torch.nn.functional as F
                out1 = p1.get_output()
                out2 = p2.get_output()

                # ğŸ”¥ è‡ªåŠ¨è¡¥é›¶åˆ°å½“å‰ç¯å¢ƒ target_dim
                target_dim = self.env_size * self.env_size * 2

                if out1.shape[-1] < target_dim:
                    padding = (0, target_dim - out1.shape[-1])
                    out1 = torch.nn.functional.pad(out1, padding, value=0)

                if out2.shape[-1] < target_dim:
                    padding = (0, target_dim - out2.shape[-1])
                    out2 = torch.nn.functional.pad(out2, padding, value=0)

                sim_p = F.cosine_similarity(out1, out2, dim=-1).item()

                out_e1 = e1.get_output()
                out_e2 = e2.get_output()

                # ğŸ”¥ è¡¥é›¶åˆ°å½“å‰ç¯å¢ƒé¢„æœŸå°ºå¯¸
                target_dim = self.env_size * self.env_size * 2

                if out_e1.shape[-1] < target_dim:
                    padding = (0, target_dim - out_e1.shape[-1])
                    out_e1 = F.pad(out_e1, padding, value=0)

                if out_e2.shape[-1] < target_dim:
                    padding = (0, target_dim - out_e2.shape[-1])
                    out_e2 = F.pad(out_e2, padding, value=0)

                sim_e = F.cosine_similarity(out_e1, out_e2, dim=-1).item()

                if sim_p > 0.95 and sim_e > 0.95:
                    # âœ… æ»¡è¶³é‡æ„æ¡ä»¶
                    print(f"[é‡æ„è§¦å‘] å­å›¾ ({p1.id}â†’{e1.id}) ä¸ ({p2.id}â†’{e2.id}) ç›¸ä¼¼ï¼Œå¼€å§‹é‡æ„")

                    # åˆ›å»ºæ–°å•å…ƒ
                    new_p = CogUnit(role="processor")
                    new_e = CogUnit(role="emitter")
                    new_p.state = (p1.state + p2.state) / 2
                    new_p.last_output = (p1.last_output + p2.last_output) / 2
                    new_e.state = (e1.state + e2.state) / 2
                    new_e.last_output = (e1.last_output + e2.last_output) / 2

                    new_p.energy = p1.energy + p2.energy + 0.1
                    new_e.energy = e1.energy + e2.energy + 0.1

                    # æ’å…¥æ–°å•å…ƒ
                    self.add_unit(new_p)
                    self.add_unit(new_e)
                    self.connect(new_p, new_e)

                    # å°†æ‰€æœ‰è¿æ¥åˆ° p1 / p2 çš„ä¸Šæ¸¸æŒ‡å‘ new_p
                    for uid in self.unit_map:
                        if p1.id in self.connections.get(uid, {}) or p2.id in self.connections.get(uid, {}):
                            self.connect(self.unit_map[uid], new_p)

                    # åˆ é™¤åŸå­å›¾
                    print(f"[é‡æ„åˆ é™¤] åˆ é™¤åŸå­å›¾ ({p1.id}â†’{e1.id}) å’Œ ({p2.id}â†’{e2.id})")
                    self.remove_unit(p1)
                    self.remove_unit(p2)
                    self.remove_unit(e1)
                    self.remove_unit(e2)

                    return  # æ¯è½®åªé‡æ„ä¸€ç»„ï¼Œé¿å…å†²çª

    def assign_subsystems(self, min_size=3, max_size=10):
        """
        è‡ªåŠ¨å‘ç°å±€éƒ¨é«˜å¯†åº¦è¿æ¥åŒºåŸŸï¼Œæ ‡è®°ä¸ºå­ç³»ç»Ÿ
        """
        visited = set()
        subsystem_count = 0

        for unit in self.units:
            if unit.id in visited:
                continue

            # ä»¥å½“å‰unitä¸ºèµ·ç‚¹ï¼Œåšå±€éƒ¨DFS
            cluster = self._dfs_collect_cluster(unit, max_depth=2)

            if min_size <= len(cluster) <= max_size:
                subsystem_id = f"subsys-{subsystem_count}"
                for u in cluster:
                    u.subsystem_id = subsystem_id
                subsystem_count += 1
                print(f"[å­ç³»ç»Ÿç”Ÿæˆ] æ–°å­ç³»ç»Ÿ {subsystem_id}ï¼ŒåŒ…å« {len(cluster)} ä¸ªå•å…ƒ")
                visited.update(u.id for u in cluster)

    def _dfs_collect_cluster(self, start_unit, max_depth=2):
        """
        è¾…åŠ©ï¼šæ·±åº¦ä¼˜å…ˆæœç´¢ï¼Œæ‰¾å‡ºå±€éƒ¨è¿æ¥çš„å•å…ƒç¾¤
        """
        cluster = set()
        stack = [(start_unit, 0)]
        while stack:
            unit, depth = stack.pop()
            if depth > max_depth or unit in cluster:
                continue
            cluster.add(unit)
            for neighbor in self.connections.get(unit, []):
                stack.append((neighbor, depth + 1))
        return list(cluster)

    def prune_connections(self, prune_ratio=0.2, strengthen_ratio=1.5):
        """
        è‡ªåŠ¨å‰ªæ‰ä½æ•ˆè¿æ¥ï¼Œå¼ºåŒ–é«˜æ•ˆè¿æ¥
        :param prune_ratio: å°äºå…¨å±€å¹³å‡è°ƒç”¨é¢‘ç‡ * prune_ratio çš„è¿æ¥ä¼šè¢«å‰ªæ‰
        :param strengthen_ratio: å¤§äºå…¨å±€å¹³å‡è°ƒç”¨é¢‘ç‡ * strengthen_ratio çš„è¿æ¥ä¼šè¢«å¼ºåŒ–
        """
        if not self.connection_usage:
            return

        usage_values = list(self.connection_usage.values())
        avg_usage = sum(usage_values) / len(usage_values)

        to_prune = []
        to_strengthen = []

        for conn, usage in self.connection_usage.items():
            if usage < avg_usage * prune_ratio:
                to_prune.append(conn)
            elif usage > avg_usage * strengthen_ratio:
                to_strengthen.append(conn)

        # å‰ªæ‰ä½æ•ˆè¿æ¥
        for conn in to_prune:
            from_unit, to_unit = conn
            if to_unit in self.connections.get(from_unit, []):
                self.connections[from_unit].remove(to_unit)
            print(f"[å‰ªæ] è¿æ¥ {from_unit} â†’ {to_unit} è¢«å‰ªæ‰")
            # ä¹Ÿåˆ æ‰ usageè®°å½•
            if conn in self.connection_usage:
                del self.connection_usage[conn]

        # å¼ºåŒ–é«˜æ•ˆè¿æ¥ï¼ˆå¯é€‰ï¼šæ¯”å¦‚å¢åŠ èƒ½é‡ä¼ é€’æƒé‡ç­‰ï¼‰
        for conn in to_strengthen:
            # ç®€å•æ‰“å°æ ‡è®°ï¼Œå¯ä»¥åç»­åŠ çœŸå®æƒé‡ç³»ç»Ÿ
            print(f"[å¼ºåŒ–] è¿æ¥ {conn[0]} â†’ {conn[1]} è¢«å¼ºåŒ–")

        print(f"[å‰ªæ] å‰ªæ‰ {len(to_prune)} æ¡å¼±è¿æ¥ï¼Œå¼ºåŒ– {len(to_strengthen)} æ¡å¼ºè¿æ¥")

    def auto_connect(self):
        for unit in self.units:
            # åªå¤„ç† processor èŠ‚ç‚¹
            if unit.get_role() != "processor":
                continue

            # è·å–å·²æœ‰è¿æ¥æ•°ï¼ˆä¸‹æ¸¸ï¼‰
            current_connections = self.connections[unit.id]
            if len(current_connections) < 2:
                # éšæœºæ‰¾ä¸€ä¸ª emitter æˆ– processor æ¥è¿æ¥
                def euclidean(p1, p2):
                    return ((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2) ** 0.5

                u_pos = unit.get_position()
                candidates = [
                    u for u in self.units
                    if u.id != unit.id and u.get_role() in ["processor", "emitter"] and abs(u.input_size - unit.input_size) <= 100
                       and u.id not in self.connections[unit.id]
                       and euclidean(u_pos, u.get_position()) < 3
                ]
                if not candidates:
                    # âœ… æ²¡æœ‰è¿‘é‚»ä¹Ÿå…è®¸å…¨å±€æœç´¢ emitter å»ºè¿
                    candidates = [u for u in self.units if
                                  u.id != unit.id and u.get_role() in ["processor", "emitter"] and u.id not in
                                  self.connections[unit.id]]

                # æŒ‰èƒ½é‡ä»é«˜åˆ°ä½æ’åºï¼Œä¼˜å…ˆé€‰æ‹©æœ€æœ‰ä»·å€¼è¿æ¥ç›®æ ‡
                if candidates:
                    def connection_strength(u):
                        incoming_count = sum(u.id in self.connections.get(fid, {}) for fid in self.unit_map)
                        return u.energy + incoming_count * 0.1

                    candidates.sort(key=connection_strength, reverse=True)

                    target = candidates[0]  # èƒ½é‡æœ€é«˜è€…
                    self.connect(unit, target)
                    if target.id not in current_connections:
                        self.connect(unit, target)
                        print(f"[æ–°è¿æ¥] {unit.id} â†’ {target.id}")
        # === éšæœºçªå˜è¿æ¥ï¼šprocessor æœ‰å°æ¦‚ç‡è¿æ¥æ–°ç›®æ ‡ ===
        if random.random() < 0.1:  # 10% æ¦‚ç‡è§¦å‘çªå˜
            from_candidates = [u for u in self.units if u.get_role() == "processor"]
            to_candidates = [u for u in self.units if u.get_role() in ["processor", "emitter"]]

            if from_candidates and to_candidates:
                from_unit = random.choice(from_candidates)
                to_unit = random.choice(to_candidates)

                if to_unit.id not in self.connections.get(from_unit.id, []):
                    self.connect(from_unit, to_unit)
                    print(f"[çªå˜è¿æ¥] {from_unit.id} â†’ {to_unit.id}")



    # === åˆ†åŒ–æœºåˆ¶ï¼šç»“æ„å¤±è¡¡æ—¶çš„è§’è‰²è°ƒæ•´ ===
    def rebalance_cell_types(self):
        from collections import Counter
        role_counts = Counter([unit.get_role() for unit in self.units])

        sensor_count = role_counts.get("sensor", 0)
        processor_count = role_counts.get("processor", 0)
        emitter_count = role_counts.get("emitter", 0)

        total = sensor_count + processor_count + emitter_count
        if total < 5:
            return  # ç³»ç»Ÿå¤ªå°ï¼Œä¸è¿›è¡Œè°ƒæ§

        def pick_weakest(units):
            return min(units, key=lambda u: (u.energy, getattr(u, "avg_recent_calls", 0.0)))

        # ğŸ§  1ï¸âƒ£ å¦‚æœ processor å¤ªå¤šï¼Œåˆ†åŒ–ä¸º sensor æˆ– emitterï¼ˆè°å°‘å°±åˆ†åŒ–æˆè°ï¼‰
        if (processor_count > sensor_count * 2.5 or processor_count > emitter_count * 2.5):
            candidates = [u for u in self.units if u.get_role() == "processor"]
            if not candidates:
                return
            target = pick_weakest(candidates)

            if sensor_count < emitter_count:
                print(f"[åˆ†åŒ–] processor {target.id} â†’ sensorï¼ˆå¹³è¡¡ï¼‰")
                target.role = "sensor"
                target.gene["sensor_bias"] = 1.0
            else:
                print(f"[åˆ†åŒ–] processor {target.id} â†’ emitterï¼ˆå¹³è¡¡ï¼‰")
                target.role = "emitter"
                target.gene["emitter_bias"] = 1.0

            target.age = 0
            target.energy += 0.2
            return

        # ğŸ§  2ï¸âƒ£ sensor å¤ªå¤šï¼Œåˆ†åŒ–ä¸º emitter
        if sensor_count > emitter_count * 1.5:
            candidates = [u for u in self.units if u.get_role() == "sensor"]
            if not candidates:
                return
            target = pick_weakest(candidates)
            print(f"[åˆ†åŒ–] sensor {target.id} â†’ emitterï¼ˆå¹³è¡¡ï¼‰")
            target.role = "emitter"
            target.gene["emitter_bias"] = 1.0
            target.age = 0
            target.energy += 0.2
            return

        # ğŸ§  3ï¸âƒ£ emitter å¤ªå¤šï¼Œåˆ†åŒ–ä¸º sensor
        if emitter_count > sensor_count * 1.5:
            candidates = [u for u in self.units if u.get_role() == "emitter"]
            if not candidates:
                return
            target = pick_weakest(candidates)
            print(f"[åˆ†åŒ–] emitter {target.id} â†’ sensorï¼ˆå¹³è¡¡ï¼‰")
            target.role = "sensor"
            target.gene["sensor_bias"] = 1.0
            target.age = 0
            target.energy += 0.2
            return

    def trace_info_paths(self):
        print(f"[ä¿¡æ¯è·¯å¾„è¿½è¸ª] æ­¥æ•° {self.current_step}")
        for emitter in self.units:
            if emitter.get_role() != "emitter":
                continue

            # è¿½æº¯ä¸Šæ¸¸ processor
            emit_from = [pid for pid in self.unit_map if emitter.id in self.connections.get(pid, {})]
            for pid in emit_from:
                proc_from = [sid for sid in self.unit_map if pid in self.connections.get(sid, {})]
                for sid in proc_from:
                    print(f"  sensor:{sid} â†’ processor:{pid} â†’ emitter:{emitter.id}")


    def step(self, input_tensor: torch.Tensor):
        if self.current_step == 10000:
            self.subsystem_competition = True
            print("[è¿›åŒ–] å­ç³»ç»Ÿç«äº‰æœºåˆ¶å·²æ¿€æ´»ï¼ˆSubsystem Competitionï¼‰")

        if self.current_step == 2000:
            for unit in self.units:
                unit.dynamic_aging = True
            print("[è¿›åŒ–] åŠ¨æ€å¯¿å‘½æœºåˆ¶å·²æ¿€æ´»ï¼ˆDynamic Agingï¼‰")

        if self.current_step > 3000 and self.current_step % 100 == 0:
            total_e = self.total_energy()
            if total_e > self.max_total_energy * 2.5:  # è¶…è¿‡åˆå§‹æœ€å¤§èƒ½é‡2.5å€
                tax = total_e * 0.01
                loss_per_unit = tax / max(len(self.units), 1)
                for unit in self.units:
                    unit.energy -= loss_per_unit
                print(f"[èƒ½é‡ç¨] ç¬¬ {self.current_step} æ­¥ï¼Œæ€»èƒ½é‡è¿‡é«˜ï¼Œæ‰£é™¤ {tax:.2f} èƒ½é‡")

        # === Curriculum Learning: æ¯500æ­¥æ‰©å±•ä¸€æ¬¡ç¯å¢ƒå¤§å°
        if self.current_step > 0 and self.current_step % 500 == 0:
            old_size = self.env_size
            self.env_size = min(self.env_size + 5, 20)  # æ¯æ¬¡+5ï¼Œæœ€å¤§åˆ°20x20
            self.env = GridEnvironment(size=self.env_size)  # é‡æ–°ç”Ÿæˆç¯å¢ƒ
            new_target = (random.randint(0, self.env_size - 1), random.randint(0, self.env_size - 1))
            self.task = TaskInjector(target_position=new_target)
            self.target_vector = self.task.encode_goal(self.env_size)
            print(
                f"[Curriculumå‡çº§] ç¬¬ {self.current_step} æ­¥ï¼šç¯å¢ƒå¤§å° {old_size}x{old_size} â†’ {self.env_size}x{self.env_size}ï¼Œæ–°ç›®æ ‡ {new_target}")

        if self.current_step > 0 and self.current_step % 100 == 0:
            old_max = self.max_total_energy
            self.max_total_energy *= 1.1
            print(f"[èµ„æºæ‰©å±•] ç¬¬ {self.current_step} æ­¥ï¼šMAX_TOTAL_ENERGY {old_max:.1f} â†’ {self.max_total_energy:.1f}")

        # è‹¥å½“å‰æ­¥æ•°éå¸¸æ—©æœŸï¼Œç»™äºˆåŸºç¡€èƒ½é‡è¡¥å¿
        if self.current_step < 10:
            for unit in self.units:
                if unit.get_role() != "sensor":
                    unit.energy += 0.1
                    print(f"[é¢„çƒ­è¡¥å¿] {unit.id} åˆå§‹é˜¶æ®µè·å¾—èƒ½é‡ +0.01")

        if self.current_step > 0 and self.current_step % 100 == 0:
            old_target = self.target_vector.clone()
            self.target_vector = torch.rand_like(self.target_vector)

            similarity = torch.cosine_similarity(old_target, self.target_vector, dim=0).item()
            print(f"[ç›®æ ‡å˜åŒ–] ç¬¬ {self.current_step} æ­¥ï¼Œtarget_vector æ›´æ–°ï¼ï¼ˆç›¸ä¼¼åº¦ {similarity:.3f}ï¼‰")

        if self.current_step > 0 and self.current_step % 100 == 0:
            self.prune_connections()

        if self.current_step > 0 and self.current_step % 300 == 0:
            self.assign_subsystems()

        if hasattr(self, "subsystem_competition") and self.subsystem_competition:
            if self.current_step % 1000 == 0:
                subsystem_energies = {}
                for unit in self.units:
                    if unit.subsystem_id:
                        subsystem_energies.setdefault(unit.subsystem_id, 0)
                        subsystem_energies[unit.subsystem_id] += unit.energy

                if len(subsystem_energies) >= 5:  # è‡³å°‘5ä¸ªå­ç³»ç»Ÿæ‰ç«äº‰
                    weakest = min(subsystem_energies, key=lambda x: subsystem_energies[x])
                    print(f"[å­ç³»ç»Ÿç«äº‰] æ·˜æ±°èƒ½é‡æœ€å¼±çš„å­ç³»ç»Ÿ {weakest}")

                    # åˆ é™¤å¼±å­ç³»ç»Ÿçš„æ‰€æœ‰å•å…ƒ
                    self.units = [u for u in self.units if u.subsystem_id != weakest]
                    self.unit_map = {u.id: u for u in self.units}
                    self.connections = {u.id: {} for u in self.units}

        self.current_step += 1

        # è®¡ç®—å½“å‰å„è§’è‰²å•å…ƒæ€»æ•°ï¼Œä¾›ç´§æ€¥å¢æ®–åˆ¤æ–­ä½¿ç”¨
        sensor_count = sum(1 for u in self.units if u.get_role() == "sensor")
        processor_count = sum(1 for u in self.units if u.get_role() == "processor")
        emitter_count = sum(1 for u in self.units if u.get_role() == "emitter")
        for unit in self.units:
            unit.global_sensor_count = sensor_count
            unit.global_processor_count = processor_count
            unit.global_emitter_count = emitter_count

        new_units = []  # æ–°ç”Ÿæˆçš„å•å…ƒï¼ˆå¤åˆ¶ï¼‰
        output_buffer = {}  # ç¼“å­˜æ¯ä¸ªå•å…ƒçš„è¾“å‡º {unit_id: output_tensor}

        # âœ… ç»Ÿè®¡å½“å‰å„è§’è‰²å•å…ƒæ•°é‡
        emitter_count = sum(1 for u in self.units if u.get_role() == "emitter")
        processor_count = sum(1 for u in self.units if u.get_role() == "processor")
        sensor_count = sum(1 for u in self.units if u.get_role() == "sensor")

        # âœ… å†™å…¥åˆ°æ‰€æœ‰å•å…ƒçš„å±æ€§é‡Œï¼Œä¾› should_split() ä½¿ç”¨
        for unit in self.units:
            unit.global_emitter_count = emitter_count
            unit.global_processor_count = processor_count
            unit.global_sensor_count = sensor_count

        # === ç³»ç»Ÿæ€»èƒ½é‡é™åˆ¶ï¼Œä¿æŠ¤ clone ===
        allow_clone = self.total_energy() < self.max_total_energy

        # === ç¬¬ä¸€é˜¶æ®µï¼šå•å…ƒæ›´æ–°å¤„ç† ===
        # ç»Ÿè®¡å½“å‰ emitter æ•°é‡
        emitter_count = sum(1 for u in self.units if u.get_role() == "emitter")

        for unit in self.units:
            unit.global_emitter_count = emitter_count

        for unit in self.units[:]:
            env_state = torch.from_numpy(self.env.get_state()).float()
            goal_tensor = self.task.encode_goal(self.env_size)
            unit_input = torch.cat([env_state, goal_tensor], dim=0).unsqueeze(0)

            # å¦‚æœè¯¥å•å…ƒæœ‰ä¸Šæ¸¸è¿æ¥ï¼ˆè¢«å…¶ä»–å•å…ƒæŒ‡å‘ï¼‰
            incoming = [uid for uid in self.unit_map if unit.id in self.connections.get(uid, [])]
            for uid in incoming:
                self.connection_usage[(uid, unit.id)] = self.current_step
                # å¢å¼ºå¼ºåº¦
                for uid in incoming:
                    self.connections[uid][unit.id] *= 1.05  # å¢å¼º 5%
                    self.connections[uid][unit.id] = min(self.connections[uid][unit.id], 5.0)  # ä¸Šé™

            if unit.get_role() == "sensor":
                env_state = torch.from_numpy(self.env.get_state()).float()
                goal_tensor = self.task.encode_goal(self.env_size)
                sensor_input = torch.cat([env_state, goal_tensor], dim=0)
                unit_input = sensor_input.unsqueeze(0)

            elif incoming:
                weighted_outputs = []
                total_weight = 0.0
                for uid in incoming:
                    strength = self.connections[uid][unit.id]
                    output = self.unit_map[uid].get_output().squeeze(0)  # ç»Ÿä¸€ä¸º [8]
                    if output.shape[0] != self.env_size * self.env_size * 2:
                        # å¦‚æœè¾“å‡ºç»´åº¦å°äºå½“å‰ç¯å¢ƒé¢„æœŸï¼Œè¡¥é›¶
                        padding = (0, self.env_size * self.env_size * 2 - output.shape[0])
                        output = torch.nn.functional.pad(output, padding, value=0)

                    weighted_outputs.append(output * strength)
                    total_weight += strength

                if total_weight > 0:
                    unit_input = torch.stack(weighted_outputs).sum(dim=0, keepdim=True) / total_weight
                else:
                    unit_input = torch.zeros_like(input_tensor).unsqueeze(0)
            else:
                # å¼ºåˆ¶ä½¿ç”¨é›¶è¾“å…¥è§¦å‘æ›´æ–°ï¼Œé¿å…å› æ— è¾“å…¥æ°¸è¿œä¸æ›´æ–°
                unit_input = torch.zeros(unit.input_size).unsqueeze(0)
                print(f"[é›¶è¾“å…¥] {unit.id} æ— ä¸Šæ¸¸è¿æ¥ï¼Œä½¿ç”¨é›¶è¾“å…¥æ›´æ–°")

            # æ‰§è¡Œå•å…ƒçš„æ›´æ–°é€»è¾‘
            # === ç»Ÿè®¡è°ƒç”¨é¢‘ç‡ï¼ˆè¿™é‡Œå¯ä»¥æ›´ç²¾ç»†ï¼Œæ¯”å¦‚ sliding windowï¼‰===
            incoming = [uid for uid in self.unit_map if unit.id in self.connections.get(uid, {})]
            unit.recent_calls = len(incoming)  # è¡¨ç¤ºè¿™ä¸ªå•å…ƒåœ¨è¿™ä¸€æ­¥è¢«å¤šå°‘ä¸Šæ¸¸è°ƒç”¨
            unit.connection_count = len(self.connections.get(unit.id, {}))  # ç›´æ¥ä¸‹æ¸¸è¿æ¥æ•°é‡
            # æ›´æ–°è°ƒç”¨å†å²è®°å½•
            unit.call_history.append(unit.recent_calls)
            if len(unit.call_history) > unit.call_window:
                unit.call_history.pop(0)

            # è®¡ç®—å¹³å‡è°ƒç”¨é¢‘ç‡
            unit.avg_recent_calls = sum(unit.call_history) / len(unit.call_history)

            if unit.recent_calls == 0:
                unit.inactive_steps += 1
            else:
                unit.inactive_steps = 0  # é‡ç½®

            unit.current_step = self.current_step
            # === ç»Ÿä¸€åŠ¨æ€èƒ½é‡æ¶ˆè€— ===
            var = torch.var(unit_input).item()
            freq = unit.recent_calls
            conn = unit.connection_count
            call_density = freq / (conn + 1)
            conn_strength_sum = sum(self.connections.get(unit.id, {}).values())

            # ç»Ÿä¸€ä»£è°¢æ¨¡å‹ï¼ˆå¯è°ƒæƒé‡ï¼‰
            dim_scale = 50.0 / unit.input_size  # â† 50 æ˜¯æœ€åˆç¯å¢ƒ(5Ã—5Ã—2)çš„åŸºå‡†
            bias_factor = 1.0
            if unit.role == "sensor":
                bias_factor = unit.gene.get("sensor_bias", 1.0)
            elif unit.role == "processor":
                bias_factor = unit.gene.get("processor_bias", 1.0)
            elif unit.role == "emitter":
                bias_factor = unit.gene.get("emitter_bias", 1.0)

            decay = (var * 0.1 + call_density * 0.008 + conn_strength_sum * 0.004) * dim_scale * bias_factor

            unit.energy -= decay
            unit.energy = max(unit.energy, 0.0)

            print(
                f"[ä»£è°¢] {unit.id} var={var:.3f}, freq={freq}, conn={conn}, strength_sum={conn_strength_sum:.2f} â†’ -{decay:.3f} èƒ½é‡")

            unit.update(unit_input)
            # âœ… åŠ å¼ºè¿æ¥æƒé‡ï¼ˆä½¿ç”¨æ¬¡æ•°è¶Šå¤šè¶Šå¼ºï¼‰
            for uid in incoming:
                if unit.id in self.connections.get(uid, {}):
                    self.connections[uid][unit.id] *= 1.05  # å¢å¼º
                    self.connections[uid][unit.id] = min(self.connections[uid][unit.id], 5.0)
            output_buffer[unit.id] = unit.get_output()
            print(unit)

            # === åˆ¤æ–­æ˜¯å¦éœ€è¦å¤åˆ¶ ===
            if allow_clone and unit.should_split():
                # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦æ‰©å±•è¿‡ï¼Œå†³å®šæ˜¯å¦ç»™æ–°input_size
                expected_input_size = self.env_size * self.env_size * 2
                new_input_size = None
                if unit.input_size != expected_input_size:
                    new_input_size = expected_input_size

                # è®°å½•ä¸Šä¸‹æ¸¸è¿æ¥
                incoming_ids = [uid for uid in self.unit_map if unit.id in self.connections.get(uid, {})]
                outgoing_ids = list(self.connections.get(unit.id, {}).keys())

                # å…‹éš†æ–°ç»†èƒ
                child = unit.clone(new_input_size=new_input_size)
                new_units.append(child)

                # çˆ¶å­è¿æ¥
                self.connect(unit, child)

                # âœ… å…‹éš†ç»§æ‰¿ä¸Šæ¸¸è¿æ¥
                for uid in incoming_ids:
                    if uid in self.unit_map:
                        self.connect(self.unit_map[uid], child)
                        print(f"[è¿æ¥ç»§æ‰¿] ä¸Šæ¸¸ {uid} â†’ å­å•å…ƒ {child.id}")

                # âœ… å…‹éš†ç»§æ‰¿ä¸‹æ¸¸è¿æ¥
                for uid in outgoing_ids:
                    if uid in self.unit_map:
                        self.connect(child, self.unit_map[uid])
                        print(f"[è¿æ¥ç»§æ‰¿] å­å•å…ƒ {child.id} â†’ ä¸‹æ¸¸ {uid}")


            else:
                if not allow_clone:
                    print(f"[ç³»ç»Ÿä¿æŠ¤] æ€»èƒ½é‡è¿‡é«˜ï¼Œç¦æ­¢ {unit.id} åˆ†è£‚")

            # === åˆ¤æ–­æ˜¯å¦æ­»äº¡ ===
            if unit.should_die():
                print(f"[æ­»äº¡] {unit.id} è¢«ç§»é™¤")
                self.remove_unit(unit)

        # å°†æ‰€æœ‰æ–°ç”Ÿæˆçš„å•å…ƒåŠ å…¥å›¾ç»“æ„
        for unit in new_units:
            self.add_unit(unit)

        self.auto_connect()
        # === æ­»è¿æ¥æ¸…ç† ===
        if self.current_step % 10 == 0:
            threshold = 50
            for from_id in list(self.connections.keys()):
                for to_id in list(self.connections[from_id].keys()):
                    last_used = self.connection_usage.get((from_id, to_id), -1)
                    if self.current_step - last_used > threshold:
                        del self.connections[from_id][to_id]  # âœ… æ­£ç¡®åˆ é™¤æ–¹å¼
                        print(f"[æ­»è¿æ¥æ¸…é™¤] {from_id} â†’ {to_id}")
                        # åˆ é™¤è¿æ¥åï¼Œç»™ from_unit è½»å¾®èƒ½é‡æƒ©ç½š
                        if from_id in self.unit_map:
                            self.unit_map[from_id].energy -= 0.01  # å¯è°ƒå‚æ•°
                            print(f"[æƒ©ç½š] {from_id} å› è¿æ¥å¤±æ•ˆï¼Œèƒ½é‡ -0.01")
                    else:
                        # âœ… å‰Šå¼±ä»åœ¨ç”¨ä½†è¡¨ç°å·®çš„è¿æ¥
                        self.connections[from_id][to_id] *= 0.95
                        if self.connections[from_id][to_id] < 0.1:
                            del self.connections[from_id][to_id]
                            print(f"[è¿æ¥è¡°å‡æ¸…é™¤] {from_id} â†’ {to_id}")

        # ç®€æ˜“ä»»åŠ¡å¥–åŠ±ï¼šå¦‚æœ emitter è¾“å‡ºé è¿‘æŸä¸ªç›®æ ‡å‘é‡ï¼Œåˆ™å‘æ”¾å¥–åŠ±
        target_vector = self.target_vector
        outputs = self.collect_emitter_outputs()
        if outputs is not None:
            avg_output = outputs.mean(dim=0)
            distance = torch.norm(avg_output - target_vector)

            # çº¿æ€§è¡°å‡å¼å¥–åŠ±åˆ†æ•°ï¼ˆè·ç¦» 0â†’å¥–åŠ±æ»¡åˆ†1ï¼Œè·ç¦»3â†’å¥–åŠ±ä¸º0ï¼‰
            reward_score = max(0.0, 1.0 - distance / 10.0)

            if reward_score > 0.0:
                dim_scale = self.target_vector.size(0) / 50  # 50 â†’ åŸå§‹åŸºå‡†
                dilution_factor = 1.0
                if self.current_step >= 5000:  # 5000æ­¥åå¼€å§‹å¥–åŠ±ç¨€é‡Š
                    dilution_factor = max(0.5, 1.0 - 0.00005 * (self.current_step - 5000))

                for unit in self.units:
                    if unit.get_role() == "processor":
                        unit.energy += 0.04 * dim_scale * reward_score * dilution_factor
                    elif unit.get_role() == "emitter":
                        unit.energy += 0.02 * dim_scale * reward_score * dilution_factor

                print(f"[å¥–åŠ±] è¾“å‡ºæ¥è¿‘ç›®æ ‡ï¼Œè·ç¦» {distance:.2f}ï¼Œå¥–åŠ±æ¯”ç‡ {reward_score:.2f} â†’ èƒ½é‡åˆ†é…å®Œæ¯•")

            # âœ… å¢åŠ å¤šæ ·æ€§æƒ©ç½šï¼ˆå«æ•°é‡åˆ¤æ–­ï¼‰
            action_indices = [torch.argmax(out).item() for out in outputs]

            if len(action_indices) >= 3:  # è‡³å°‘ 3 ä¸ª emitter æ‰æœ‰ç»Ÿè®¡æ„ä¹‰
                common_action = max(set(action_indices), key=action_indices.count)
                if action_indices.count(common_action) > len(action_indices) * 0.9:
                    for unit in self.units:
                        if unit.get_role() == "emitter":
                            unit.energy -= 0.02
                            print(f"[æƒ©ç½š] emitter {unit.id} å› è¾“å‡ºå•ä¸€è¡Œä¸ºè¢«æ‰£èƒ½é‡")
                elif len(set(action_indices)) > len(action_indices) * 0.6:
                    for unit in self.units:
                        if unit.get_role() == "emitter":
                            unit.energy += 0.02
                    print(f"[å¥–åŠ±] emitter è¾“å‡ºå¤šæ ·æ€§é«˜ â†’ æ‰€æœ‰ emitter +0.02 èƒ½é‡")

            else:
                print(f"[è·³è¿‡å¤šæ ·æ€§æƒ©ç½š] emitter æ•°é‡ä¸è¶³ï¼Œä»… {len(action_indices)} ä¸ª")

            if task.evaluate(env, outputs):
                print(f"[ä»»åŠ¡å®Œæˆ] è¾¾æˆç›®æ ‡ä½ç½® {task.target_position}ï¼Œå¥–åŠ± +0.1")
                for unit in self.units:
                    if unit.get_role() == "processor":
                        unit.energy += 0.1

        self.trace_info_paths()
        # âœ… æ‰§è¡Œç»“æ„å†—ä½™åˆå¹¶
        self.merge_redundant_units()
        self.restructure_common_subgraphs()

        # âœ… æ‰“å°å½“å‰å„ç±»å‹ç»†èƒæ•°é‡
        from collections import Counter
        role_counts = Counter([unit.get_role() for unit in self.units])
        print("[ç»†èƒç»Ÿè®¡] å½“å‰å„ç±»æ•°é‡ï¼š", dict(role_counts))

        print("[è¿æ¥å¼ºåº¦]")
        for from_id, to_dict in self.connections.items():
            for to_id, strength in to_dict.items():
                print(f"  {from_id} â†’ {to_id} = {strength:.3f}")
                # ç»Ÿè®¡å„ç±»å•å…ƒæ•°é‡
                sensor_count = sum(1 for u in self.units if u.get_role() == "sensor")
                processor_count = sum(1 for u in self.units if u.get_role() == "processor")
                emitter_count = sum(1 for u in self.units if u.get_role() == "emitter")
                print(f"[ç»Ÿè®¡] sensor: {sensor_count}, processor: {processor_count}, emitter: {emitter_count}")

        self.rebalance_cell_types()

    def summary(self):
        # æ‰“å°å½“å‰å›¾ç»“æ„æ¦‚å†µ
        print(f"[å›¾ç»“æ„] å½“å‰å•å…ƒæ•°: {len(self.units)}")
        for unit in self.units:
            print(f" - {unit} â†’ è¿æ¥æ•°: {len(self.connections[unit.id])}")

    def collect_emitter_outputs(self):
        outputs = []
        for unit in self.units:
            if unit.get_role() == "emitter":
                output = unit.get_output()
                if output.shape[-1] == self.target_vector.shape[0]:
                    if output.dim() == 1:
                        output = output.unsqueeze(0)
                    outputs.append(output)

                else:
                    print(
                        f"[è­¦å‘Š] emitter {unit.id} è¾“å‡ºç»´åº¦ {output.shape[-1]} ä¸ç›®æ ‡ {self.target_vector.shape[0]} ä¸åŒ¹é…ï¼Œå¿½ç•¥")

        if outputs:
            stacked = torch.stack(outputs)
            print("[è¾“å‡ºæ£€æŸ¥] Emitter è¾“å‡ºå‡å€¼ï¼ˆå‰5ç»´ï¼‰:", stacked.mean(dim=0)[:5])
            return stacked
        else:
            print("[è¾“å‡ºæ£€æŸ¥] å½“å‰æ²¡æœ‰æ´»è·ƒçš„ emitter å•å…ƒ")
            return None


def interpret_emitter_output(output_tensor):
    """
    å°† emitter çš„è¾“å‡ºå‘é‡è§£é‡Šä¸ºåŠ¨ä½œã€‚
    """
    action_names = [f"åŠ¨ä½œ{i}" for i in range(50)]
    if output_tensor.dim() == 3:
        output_tensor = output_tensor.squeeze(1)  # å˜æˆ [N, 8]

    for i, out in enumerate(output_tensor):
        action_index = torch.argmax(out).item()
        action = action_names[action_index]
        print(f"[è¡Œä¸ºè§¦å‘] ç¬¬ {i+1} ä¸ª emitter æ‰§è¡ŒåŠ¨ä½œ: {action}")

def environment_feedback(output_tensor, graph):
    """
    ç¯å¢ƒå¯¹ emitter è¾“å‡ºçš„ç®€å•åé¦ˆæœºåˆ¶ï¼š
    - å¦‚æœè¾“å‡ºä¸­å‡ºç°ç‰¹å®šæ¨¡å¼ï¼ˆä¾‹å¦‚ â†‘ å’Œ â†’ åŒæ—¶è¾ƒå¼ºï¼‰ï¼Œå¥–åŠ±å¯¹åº” emitter
    - å¥–åŠ±é€šè¿‡æå‡ energy å®ç°
    """
    if output_tensor.dim() == 3:
        output_tensor = output_tensor.squeeze(1)  # [N, 8]

    for i, out in enumerate(output_tensor):
        # ç¤ºä¾‹æ¡ä»¶ï¼šè‹¥ â†‘ (index 0) å’Œ â†’ (index 3) è¾“å‡ºå€¼éƒ½å¤§äº 0.2
        if out[5] > 0.3 and out[13] < -0.1:  # è‡ªå®šä¹‰è§„åˆ™
            emitter = [u for u in graph.units if u.get_role() == "emitter"][i]
            emitter.energy += 0.05  # ç®€å•å¥–åŠ±
            print(f"[å¥–åŠ±] emitter {emitter.id} å›  â†‘+â†’ è¢«å¥–åŠ± +0.05 èƒ½é‡")



if __name__ == "__main__":
    env = GridEnvironment(size=5)
    # åˆå§‹åŒ–ä»»åŠ¡ç›®æ ‡ï¼ˆä¾‹å¦‚ç›®æ ‡ä½ç½®åœ¨å³ä¸‹è§’ (4, 4)ï¼‰
    task = TaskInjector(target_position=(4, 4))
    goal_tensor = task.encode_goal(env.size)  # ç”Ÿæˆ 25ç»´ one-hot å‘é‡
    graph = CogGraph()

    # åˆå§‹åŒ–å•å…ƒ
    # åˆå§‹åŒ–å•å…ƒ
    sensor = CogUnit(input_size=graph.env_size * graph.env_size * 2, role="sensor")
    emitter = CogUnit(input_size=graph.env_size * graph.env_size * 2, role="emitter")
    emitter.energy = 2.0

    # å¤šä¸ª processor
    processor_list = []
    for _ in range(5):
        p = CogUnit(input_size=graph.env_size * graph.env_size * 2, role="processor")
        p.energy = 2.0  # âœ… ç›´æ¥ç»™äºˆå¯åŠ¨èµ„é‡‘
        processor_list.append(p)

    # åŠ å…¥å›¾ç»“æ„
    graph.add_unit(sensor)
    graph.add_unit(emitter)
    for p in processor_list:
        graph.add_unit(p)

    # å»ºç«‹è¿æ¥
    for p in processor_list:
        graph.connect(sensor, p)
        graph.connect(p, emitter)

    # è¿è¡Œæ¨¡æ‹Ÿ
    for step in range(200):
        print(f"\n==== ç¬¬ {step+1} æ­¥ ====")

        # 1ï¸âƒ£ è·å–ç¯å¢ƒçŠ¶æ€ï¼Œè¾“å…¥ sensor
        state = env.get_state()
        input_tensor = torch.cat([
            torch.from_numpy(state).float(),
            goal_tensor
        ], dim=0)

        # 2ï¸âƒ£ å¯åŠ¨è®¤çŸ¥ç³»ç»Ÿï¼ˆæ„ŸçŸ¥ + å†³ç­–ï¼‰
        graph.step(input_tensor)

        # 3ï¸âƒ£ æ”¶é›† emitter è¾“å‡ºï¼Œè½¬æ¢ä¸ºåŠ¨ä½œ
        emitter_output = graph.collect_emitter_outputs()
        if emitter_output is not None:
            action_index = torch.argmax(emitter_output.mean(dim=0)).item()
            print(f"[è¡ŒåŠ¨å†³ç­–] æ‰§è¡ŒåŠ¨ä½œ: {action_index}")

            # 4ï¸âƒ£ æ‰§è¡ŒåŠ¨ä½œï¼Œæ”¹å˜ç¯å¢ƒ
            env.step(action_index)
            # ğŸ” å°†ç¯å¢ƒèƒ½é‡å˜åŒ–åé¦ˆç»™ emitter
            for unit in graph.units:
                if unit.get_role() == "emitter":
                    unit.energy += env.agent_energy_gain
                    unit.energy -= env.agent_energy_penalty
                    print(f"[ç¯å¢ƒåé¦ˆ] {unit.id} +{env.agent_energy_gain:.2f} -{env.agent_energy_penalty:.2f}")

        # 5ï¸âƒ£ æ‰“å°ç¯å¢ƒå›¾ç¤º
        env.render()

        # å¦‚æœæ²¡æœ‰å•å…ƒå‰©ä¸‹ï¼Œé€€å‡ºd
        if not graph.units:
            print("[ç»ˆæ­¢] æ‰€æœ‰å•å…ƒæ­»äº¡ã€‚")
            break

from collections import Counter
final_counts = Counter([unit.get_role() for unit in graph.units])
print("\nğŸ§¬ æœ€ç»ˆç»†èƒæ€»æ•°ç»Ÿè®¡ï¼š", dict(final_counts))
print("ğŸ”¢ æ€»ç»†èƒæ•° =", len(graph.units))
