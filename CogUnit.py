# cogunit.py
import torch
import uuid
import random
import logging
import logging
from collections import deque

# ======== CogUnit å…¨å±€åŠŸèƒ½å¼€å…³ ========
ENABLE_MINI_LEARN = False   # â† å…³é—­è‡ªç¼–ç è®­ç»ƒ
FOLLOW_INPUT_DEVICE = True  # â† è‡ªåŠ¨æŠŠå†…éƒ¨å¼ é‡è·Ÿéšè¾“å…¥ deviceï¼ˆGPU/CPUï¼‰
# å¦‚æƒ³å®Œå…¨æ‰‹åŠ¨æ§åˆ¶è¿ç§»ï¼Œæ”¹æˆ False å¹¶ä»…ç”¨ .to() æ–¹æ³•ã€‚
MAX_OUTPUT_DIM = None       # â† è‹¥è®¾ä¸º intï¼Œåˆ™ get_output() å¼ºæˆªæ–­
# ====================================


class LimitedDebugHandler(logging.Handler):
    def __init__(self, capacity=100):
        super().__init__(level=logging.DEBUG)  # åªå¤„ç† DEBUG
        self.buffer = deque(maxlen=capacity)

    def emit(self, record):
        if record.levelno == logging.DEBUG:
            try:
                msg = self.format(record)
                self.buffer.append(msg)
            except Exception:
                pass  # é˜²æ­¢æ ¼å¼åŒ–æŠ¥é”™

    def dump_to_console(self):
        print("\n==== [æœ€è¿‘ Debug æ—¥å¿—] ====")
        for msg in self.buffer:
            print(msg)

# === è®¾ç½® root logger ===
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)
logger.handlers.clear()  # âœ… é˜²æ­¢é‡å¤æ‰“å°ï¼ˆå…³é”®ä¸€æ­¥ï¼ï¼‰

# âœ… æ·»åŠ  Debug ç¼“å­˜ Handlerï¼ˆä¸ä¼šæ˜¾ç¤ºã€ä¸è¾“å‡ºã€ä»…å†…å­˜ï¼‰
debug_handler = LimitedDebugHandler(capacity=100)
debug_handler.setFormatter(logging.Formatter('%(asctime)s [DEBUG] %(message)s', datefmt='%H:%M:%S'))
logger.addHandler(debug_handler)

# âœ… æ·»åŠ æ­£å¸¸è¾“å‡º Handlerï¼ˆåªæ˜¾ç¤º INFO åŠä»¥ä¸Šï¼‰
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%H:%M:%S'))
logger.addHandler(console_handler)



# === Split-Gate åŠ¨æ€é˜ˆå€¼è¡¨ï¼ˆè¿‡é‡ä¸Šé™ï¼‰===========================
# æ¯”ä¾‹ k_esï¼šEmitter <-> Sensor   ï¼  k_pï¼š ç›¸å¯¹ Processor/2
SPLIT_HI_ES_TABLE = { 50: 1.30, 200: 1.20, 500: 1.12, float("inf"): 1.05 }
SPLIT_HI_P_TABLE  = { 50: 1.20, 200: 1.15, 500: 1.08, float("inf"): 1.03 }

TOL_FRAC_SPLIT = 0.05      # è‡³å°‘å·®å€¼ Î”â‰¥ceil(totalÃ—5 %) ï¼ˆä¸” â‰¥1ï¼‰
# ===============================================================

def _get_hi(table, total):
    """æŒ‰ç…§æ€»ç»†èƒæ•°è¿”å›å½“å‰é˜¶æ®µçš„ hi é˜ˆå€¼"""
    for lim, val in table.items():
        if total < lim:
            return val
    return table[float("inf")]



# â”€â”€ è§’è‰²åˆ†è£‚æœ€ä½èƒ½é‡é˜ˆå€¼ ä»¥åŠ æœ€ä½è°ƒç”¨é¢‘ç‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROLE_SPLIT_RULE = {
    "sensor":    {"min_e": 1.2, "min_calls": 0},   # è½»é‡ï¼Œå‡ ä¹ä¸é™åˆ¶è°ƒç”¨é¢‘ç‡
    "processor": {"min_e": 1.6, "min_calls": 1},   # ä¸­ç­‰
    "emitter":   {"min_e": 1.2, "min_calls": 2},   # æœ€é‡ï¼Œé—¨æ§›æœ€é«˜
}
# ----------------------------------------------------



class CogUnit:
    """
    CogUnit æ˜¯ EvoCore çš„æœ€å°è®¤çŸ¥å•å…ƒï¼š
    - æ‹¥æœ‰ç‹¬ç«‹çŠ¶æ€ã€èƒ½é‡ã€å¹´é¾„
    - å¯è¿›è¡ŒçŠ¶æ€æ›´æ–°ï¼ˆupdateï¼‰ä¸è¾“å‡º
    - å¯åˆ¤æ–­æ˜¯å¦åˆ†è£‚ï¼ˆshould_splitï¼‰ä¸æ­»äº¡ï¼ˆshould_dieï¼‰
    - å¯å…‹éš†ç”Ÿæˆæ–°å•å…ƒï¼ˆcloneï¼‰
    """

    def __init__(self, input_size=50, hidden_size=16, role="processor"):
        self.is_elite = False
        self.local_memory_pool = []  # æ¯ä¸ªå•å…ƒçš„ç§æœ‰è®°å¿†æ± 
        self.memory_pool_limit = 150  # æ¯ä¸ªç»†èƒè®°å¿†æ± æœ€å¤šä¿ç•™ N æ¡

        # åŸºå› è¡¨è¾¾ï¼Œè¡¨ç¤ºå¯¹ä¸åŒåŠŸèƒ½çš„åå¥½
        self.gene = {
            "sensor_bias": random.uniform(0.8, 1.2),
            "processor_bias": random.uniform(0.8, 1.2),
            "emitter_bias": random.uniform(0.8, 1.2),
            "mutation_rate": 0.001  # æ¯æ¬¡å¤åˆ¶æœ‰0.1%æ¦‚ç‡çªå˜
        }

        self.death_by_aging = False
        self.subsystem_id = None  # åˆå§‹æ²¡æœ‰å­ç³»ç»Ÿå½’å±
        self.output_history = []  # âœ… ç”¨äºè®°å½•è¿‘å‡ æ¬¡è¾“å‡ºï¼Œè¯„ä¼°æ˜¯å¦è¡Œä¸ºå•ä¸€
        self.call_history = []  # è®°å½•æœ€è¿‘å‡ æ­¥çš„è°ƒç”¨æ¬¡æ•°
        self.call_window = 5  # çª—å£é•¿åº¦ï¼Œè¿‡å» 5 æ­¥
        self.inactive_steps = 0
        self.position = (random.randint(0, 10), random.randint(0, 10))  # å¯è°ƒèŒƒå›´
        self.state_memory = []  # è®°å¿†é˜Ÿåˆ—
        self.memory_limit = 5  # å¯è°ƒæ•´ä¸º k æ­¥
        self.role = role
        self.id = uuid.uuid4()          # å”¯ä¸€æ ‡è¯†
        self.energy = 1.0               # åˆå§‹èƒ½é‡
        self.age = 0                    # ç”Ÿå­˜æ­¥æ•°
        self.input_size = input_size
        self.hidden_size = hidden_size

        # è®¤çŸ¥çŠ¶æ€å‘é‡
        self.state = torch.zeros(hidden_size)

        # å¾®å‹å‰é¦ˆç½‘ç»œï¼ˆè¾“å…¥ç»´åº¦ â†’ éšè—ç»´åº¦ â†’ å›åˆ°è¾“å…¥ç»´åº¦ï¼‰
        self.function = torch.nn.Sequential(
            torch.nn.Linear(input_size, hidden_size),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_size, input_size)
        )

        self.last_output = torch.zeros(input_size)

        if "mutation_rate" not in self.gene:
            self.gene["mutation_rate"] = 0.05
        self.device = torch.device("cpu")  # é»˜è®¤è·Ÿéš CPU

    # ---------------- æ–°å¢ ----------------
    def to(self, device):
        """æŠŠå†…éƒ¨æƒé‡ & çŠ¶æ€è¿ç§»åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆcpu / cudaï¼‰"""
        device = torch.device(device)
        self.device = device
        self.function.to(device)
        self.state = self.state.to(device)
        self.last_output = self.last_output.to(device)
        # è‹¥è¿˜æœ‰å…¶ä»–ç¼“å­˜å¼ é‡ï¼Œä¹Ÿä¸€å¹¶ .to(device)
        return self
    # -------------------------------------


    def get_position(self):
        return self.position

    def mini_learn(self, input_tensor, target_tensor, lr=0.001):
        if input_tensor.dim() == 1:
            input_tensor = input_tensor.unsqueeze(0)
        if target_tensor.dim() == 1:
            target_tensor = target_tensor.unsqueeze(0)

        # Forward
        output = self.function(input_tensor)

        # Loss
        loss = torch.nn.functional.mse_loss(output, target_tensor)

        # Backward
        self.function.zero_grad()
        loss.backward()

        # Manual parameter update
        with torch.no_grad():
            for param in self.function.parameters():
                if param.grad is not None:
                    param.copy_(param - lr * param.grad)


        logger.debug(f"[Mini-Learn] {self.id} loss={loss.item():.4f} (lr={lr})")


    def compute_self_reward(self, input_tensor, output_tensor):
        """
        ç®€å• self-rewardï¼šå¦‚æœè¾“å‡ºèƒ½è·Ÿè¾“å…¥ä¿æŒä¸€è‡´æ€§ï¼Œå°±è·å¾—å°å¥–åŠ±
        """
        if input_tensor.shape != output_tensor.shape:
            output_tensor = output_tensor[:, :input_tensor.shape[1]]  # é˜²æ­¢ç»´åº¦ä¸åŒ
        error = torch.mean((input_tensor - output_tensor) ** 2)
        reward = 0.01 * (self.input_size / 50) * (1.0 - error.item())  # errorè¶Šå°å¥–åŠ±è¶Šé«˜
        return max(reward, 0.0)  # ä¸è®©å¥–åŠ±ä¸ºè´Ÿæ•°


    def update(self, input_tensor: torch.Tensor):
        if FOLLOW_INPUT_DEVICE:
            # è‹¥è¾“å…¥åœ¨ GPUï¼Œä½† self.function è¿˜åœ¨ CPUï¼Œå°±è¿è¿‡å»
            if self.function[0].weight.device != input_tensor.device:
                self.to(input_tensor.device)

        """æ›´æ–° CogUnit çŠ¶æ€"""
        if input_tensor.dim() == 1:
            input_tensor = input_tensor.unsqueeze(0)

        # ğŸš¨ å…ˆæ£€æŸ¥ input_size æ˜¯å¦éœ€è¦æ‰©å±•ï¼ˆåŠ¨æ€é€‚é…ç¯å¢ƒå˜åŒ–ï¼‰
        current_input_size = input_tensor.shape[-1]
        if current_input_size != self.input_size:
            logger.info(f"[åŠ¨æ€æ‰©å±•] {self.id} è¾“å…¥å°ºå¯¸å˜åŒ– {self.input_size} â†’ {current_input_size}")

            # é‡å»º function ç½‘ç»œ
            self.function = torch.nn.Sequential(
                torch.nn.Linear(current_input_size, self.hidden_size),
                torch.nn.ReLU(),
                torch.nn.Linear(self.hidden_size, current_input_size)
            )
            self.input_size = current_input_size
            self.last_output = torch.zeros(current_input_size, device=input_tensor.device)

        # === Forward: å†…éƒ¨å¤„ç† ===
        raw_output = self.function(input_tensor)  # æ­£å¸¸forward
        self.last_output = raw_output.detach().clone()  # âš¡ å…³é”®ï¼šdetachæ‰ï¼Œé¿å…æ±¡æŸ“è®¡ç®—å›¾
        self.state = self.last_output.clone()

        # âœ… å­˜å‚¨è¾“å‡ºå†å²ï¼Œä¾›è¡Œä¸ºè´¨é‡åˆ¤æ–­ç”¨
        self.output_history.append(self.last_output.detach().clone())
        if len(self.output_history) > 5:
            self.output_history.pop(0)
        self.age += 1

        # === å¤–éƒ¨çŠ¶æ€è®°å¿†ï¼ˆç”¨äºåç»­å¥–åŠ±æœºåˆ¶ï¼‰ ===
        self.state_memory.append(self.state.clone())
        if len(self.state_memory) > self.memory_limit:
            self.state_memory.pop(0)

        # ========================
        # ğŸš¨ åŠ¨æ€èƒ½é‡æ¶ˆè€—é€»è¾‘éƒ¨åˆ†
        # ========================

        # 1ï¸âƒ£ è¾“å…¥å¤æ‚åº¦ï¼šä½¿ç”¨æ–¹å·®ä½œä¸ºç†µçš„è¿‘ä¼¼
        input_var = torch.var(input_tensor).item()

        # 2ï¸âƒ£ è°ƒç”¨é¢‘ç‡ï¼šå¤–éƒ¨ç”± Graph å†™å…¥ recent_calls å±æ€§
        recent_call_freq = getattr(self, "recent_calls", 1)

        # 3ï¸âƒ£ æ´»è·ƒè¿æ¥æ•°ï¼šå¤–éƒ¨ç”± Graph å†™å…¥ connection_count å±æ€§
        connection_count = getattr(self, "connection_count", 1)

        # âš ï¸ ä»£è°¢å·²ç”± CogGraph æ§åˆ¶ï¼Œè¿™é‡Œä¸å†æ¶ˆè€— energy

        # === é«˜é¢‘è°ƒç”¨å¥–åŠ±æœºåˆ¶ ===
        avg_recent_calls = getattr(self, "avg_recent_calls", 0.0)
        if avg_recent_calls >= 2.0 and self.energy > 0.0:
            self.energy += 0.01
            logger.debug(f"[å¥–åŠ±] {self.id} å¹³å‡è°ƒç”¨é¢‘ç‡ {avg_recent_calls:.2f} â†’ èƒ½é‡ +0.02")

        # === è¾“å‡ºæ‰°åŠ¨ï¼šæ¨¡æ‹Ÿæ—©æœŸæ¢ç´¢è¡Œä¸ºï¼ˆå‰10æ­¥ï¼‰===
        if hasattr(self, "current_step"):
            if self.get_role() == "emitter" and self.current_step < 20:
                noise = torch.randn_like(self.last_output) * 0.2
                self.last_output += noise
                logger.debug(f"[æ‰°åŠ¨] emitter {self.id} è¾“å‡ºåŠ å…¥æ‰°åŠ¨")
            elif self.get_role() == "processor" and self.current_step < 5:
                noise = torch.randn_like(self.last_output) * 0.1
                self.last_output += noise
                logger.debug(f"[æ‰°åŠ¨] processor {self.id} è¾“å‡ºåŠ å…¥æ‰°åŠ¨")

        # === âœ… å†…éƒ¨å¥–åŠ±æœºåˆ¶ Self-Reward ===
        self_reward = self.compute_self_reward(input_tensor, self.last_output)
        self.energy += self_reward
        if self_reward > 0:
            logger.debug(f"[å†…éƒ¨å¥–åŠ±] {self.id} è‡ªè¯„å¥–åŠ± +{self_reward:.4f} èƒ½é‡ (ç°æœ‰èƒ½é‡ {self.energy:.2f})")

        # === âœ… å±€éƒ¨å¾®å‹å­¦ä¹ 
        if self.get_role() == "emitter":
            bias = self.gene.get("emitter_bias", 1.0)
            lr = 0.001 * (2.0 - min(1.5, bias))
            if ENABLE_MINI_LEARN:
                self.mini_learn(input_tensor, self.last_output.detach(), lr=lr)

        else:
            # processor/sensor ä»æ˜¯è‡ªç¼–ç å¼
            bias = self.gene.get("processor_bias", 1.0) if self.role == "processor" else self.gene.get("sensor_bias",
                                                                                                       1.0)
            lr = 0.001 * (2.0 - min(1.5, bias))  # bias è¶Šé«˜ï¼Œå­¦ä¹ ç‡è¶Šä½ï¼Œä»£è¡¨æ›´â€œç¨³å¥â€ï¼Œè¶Šä½åˆ™æ›´æ˜“æ¿€åŠ¨
            if ENABLE_MINI_LEARN:
                self.mini_learn(input_tensor, input_tensor, lr=lr)

    def get_output(self) -> torch.Tensor:
        """è¿”å›ç»™ä¸‹æ¸¸å•å…ƒä½¿ç”¨çš„è¾“å‡º (shape=[1, input_size])"""
        if MAX_OUTPUT_DIM is not None and self.last_output.numel() > MAX_OUTPUT_DIM:
            return self.last_output[:MAX_OUTPUT_DIM]
        return self.last_output


    def should_split(self):


        emitter_count = getattr(self, "global_emitter_count", 1)
        processor_count = getattr(self, "global_processor_count", 1)
        sensor_count = getattr(self, "global_sensor_count", 1)
        total = getattr(self, "global_unit_count", 1)

        role = self.get_role()

        # âœ… å„ç±»ç»†èƒç´§æ€¥å¢æ®–
        if role == "emitter" and emitter_count <= 1:
            logger.warning(f"[ç´§æ€¥å¢æ®–] {self.id} æ˜¯å”¯ä¸€ emitterï¼Œå¼ºåˆ¶å°è¯•åˆ†è£‚å¹¶è¡¥ç»™")
            self.energy += 1.5  # ğŸ’¡ è¡¥ç»™èƒ½é‡
            return True

        if role == "processor" and processor_count <= 1:
            logger.warning(f"[ç´§æ€¥å¢æ®–] {self.id} æ˜¯å”¯ä¸€ processorï¼Œå¼ºåˆ¶å°è¯•åˆ†è£‚å¹¶è¡¥ç»™")
            self.energy += 1.5
            return True

        if role == "sensor" and sensor_count <= 1:
            logger.warning(f"[ç´§æ€¥å¢æ®–] {self.id} æ˜¯å”¯ä¸€ sensorï¼Œå¼ºåˆ¶å°è¯•åˆ†è£‚å¹¶è¡¥ç»™")
            self.energy += 1.5
            return True

        # ===ã€Split-Gate : 1 : 2 : 1 åŠ¨æ€é—¨æ§›ã€‘===========================
        total = getattr(self, "global_unit_count", sensor_count + processor_count + emitter_count)

        hi_es = _get_hi(SPLIT_HI_ES_TABLE, total)  # emitter <-> sensor
        hi_p = _get_hi(SPLIT_HI_P_TABLE, total)  # ç›¸å¯¹ processor/2
        half_p = processor_count / 2

        # å·®å€¼å¿…é¡» â‰¥1 ä¸” â‰¥ceil(totalÃ—TOL) æ‰ç®—â€œçœŸçš„å¤šâ€
        def _delta_enough(x, y):
            delta = x - y
            return delta >= max(1, int(total * TOL_FRAC_SPLIT))

        overpop = False
        if role == "emitter":
            if (_delta_enough(emitter_count, sensor_count * hi_es) or
                    _delta_enough(emitter_count, half_p * hi_p)):
                overpop = True
        elif role == "sensor":
            if (_delta_enough(sensor_count, emitter_count * hi_es) or
                    _delta_enough(sensor_count, half_p * hi_p)):
                overpop = True
        elif role == "processor":
            # processor è¶…æ ‡ï¼šå…¶ä¸€åŠç›¸å¯¹ e/s ä¹Ÿè¶…æ ‡
            if (_delta_enough(half_p, emitter_count * hi_p) or
                    _delta_enough(half_p, sensor_count * hi_p)):
                overpop = True

        if overpop:
            return False
        # ================================================================

        # è§’è‰²ä¸“å±èƒ½é‡ + è°ƒç”¨é—¨æ§› ----------------------
        rule = ROLE_SPLIT_RULE[role]
        if self.energy < rule["min_e"]:
            return False
        if role != "sensor" and self.avg_recent_calls < rule["min_calls"]:
            return False

        if len(self.output_history) >= 3:
            recent = self.output_history[-3:]
            if all(torch.equal(recent[0], o) for o in recent[1:]):
                return False

        return True

    def is_worthy_of_memory(self):
        """æ ¹æ®ä¸åŒè§’è‰²ï¼Œåˆ¤æ–­è¯¥ç»†èƒæ˜¯å¦å€¼å¾—åŠ å…¥è®°å¿†æ± """
        if self.age < 100:
            return False  # å¤ªå¹´è½»çš„ä¸è®°

        if self.role == "sensor":
            # æ„ŸçŸ¥å•å…ƒåº”å…³æ³¨è¾“å…¥å“åº”é¢‘ç‡ & èƒ½é‡åˆ©ç”¨æ•ˆç‡
            return self.avg_recent_calls > 0.6

        elif self.role == "processor":
            # å¤„ç†å•å…ƒåº”å…³æ³¨è°ƒç”¨é¢‘ç‡ & è¾“å‡ºå¤šæ ·æ€§
            if getattr(self, "avg_recent_calls", 0) < 0.75:
                return False
            if len(self.output_history) < 1:
                return False
            # variation = sum(
            #     torch.norm(self.output_history[i] - self.output_history[i + 1]).item()
            #     for i in range(len(self.output_history) - 1)
            # ) / (len(self.output_history) - 1)
            # return variation > 0.05  # è¾“å‡ºå˜åŒ–è¶³å¤Ÿä¸°å¯Œ
            return True

        elif self.role == "emitter":
            # è¡Œä¸ºå•å…ƒåº”å…³æ³¨ä»»åŠ¡å®Œæˆæƒ…å†µå’Œæ¿€æ´»é¢‘ç‡ï¼ˆæ´»è·ƒä½†éé‡å¤ï¼‰
            if self.avg_recent_calls < 1.0:
                return False
            if len(self.output_history) < 2:
                return False
            # diff = sum(
            #     torch.norm(self.output_history[i] - self.output_history[i + 1]).item()
            #     for i in range(len(self.output_history) - 1)
            # ) / (len(self.output_history) - 1)
            # return 0.01 < diff < 0.5  # å¤ªä½ä»£è¡¨é€€åŒ–ï¼Œå¤ªé«˜å¯èƒ½éšæœºæ‰°åŠ¨
            return True

        return False

    def add_to_local_memory(self):
        self.local_memory_pool = [m for m in self.local_memory_pool if "score" in m]
        # â€”â€” å¯¹é½ output_history åˆ°åŒä¸€é•¿åº¦ â€”â€”
        import torch.nn.functional as F
        aligned_history = None
        if len(self.output_history) >= 3:
            # å–æœ€å¤§å…ƒç´ æ•°é‡
            max_len = max(t.numel() for t in self.output_history)
            aligned_history = []
            for t in self.output_history:
                vec = t.view(-1)  # æ‹‰å¹³
                if vec.numel() < max_len:
                    # å³ä¾§è¡¥ 0
                    vec = F.pad(vec, (0, max_len - vec.numel()), value=0)
                else:
                    # é•¿åˆ™æˆªæ–­
                    vec = vec[:max_len]
                aligned_history.append(vec)

        if self.role == "sensor":
            # æ„ŸçŸ¥ï¼šç¨³å®šæ€§ + è¢«è°ƒç”¨é¢‘ç‡ï¼ˆå·²å¯¹é½ï¼‰
            if aligned_history:
                variation = torch.var(torch.stack(aligned_history), dim=0).mean().item()
            else:
                variation = 0
            score = getattr(self, "avg_recent_calls", 0) * 0.3 + variation * 0.2


        elif self.role == "processor":
            # å¤„ç†ï¼šè¾“å‡ºå¤šæ ·æ€§ + è°ƒç”¨é¢‘ç‡ï¼ˆå·²å¯¹é½ï¼‰
            if aligned_history:
                diffs = [
                    torch.norm(aligned_history[i] - aligned_history[i+1]).item()
                    for i in range(len(aligned_history) - 1)
                ]
                diversity = sum(diffs) / len(diffs)
            else:
                diversity = 0
            score = diversity * 0.5 + getattr(self, "avg_recent_calls", 0) * 0.3


        elif self.role == "emitter":
            # è¾“å‡ºï¼šæ´»è·ƒæ€§ + è¾“å‡ºç¨³å®šæ€§ï¼ˆå·²å¯¹é½ï¼‰
            if aligned_history:
                diffs = [
                    torch.norm(aligned_history[i] - aligned_history[i+1]).item()
                    for i in range(len(aligned_history) - 1)
                ]
                avg_diff = sum(diffs) / len(diffs)
                stability = 1.0 if 0.01 < avg_diff < 0.5 else 0.0
            else:
                stability = 0
            score = getattr(self, "avg_recent_calls", 0) * 0.5 + stability * 0.3


        else:
            score = self.energy + getattr(self, "avg_recent_calls", 0)

        """å°†è‡ªèº«å‹ç¼©ä¸ºè®°å¿†æ ¼å¼ï¼ŒåŠ å…¥ local memory pool"""
        mem = {
            "gene": self.gene.copy(),
            "output": self.last_output.clone(),
            "role": self.role,
            "age": self.age,
            "hidden_size": self.hidden_size,
            "score": score

        }
        self.local_memory_pool.append(mem)

        # æ§åˆ¶æœ€å¤§è®°å¿†æ•°é‡ï¼Œç§»é™¤æœ€å¼±
        if len(self.local_memory_pool) > self.memory_pool_limit:
            self.local_memory_pool.sort(key=lambda m: m["score"])
            self.local_memory_pool.pop(0)  # ç§»é™¤æœ€å¼±
        logger.info(
            f"[è®°å¿†åŠ å…¥] {self.id}ï¼ˆ{self.role}ï¼ŒAge={self.age}ï¼‰åŠ å…¥æœ¬åœ°è®°å¿†æ± ï¼Œè¯„åˆ†={mem['score']:.2f}ï¼Œå½“å‰å…± {len(self.local_memory_pool)} æ¡")

    def should_die(self) -> bool:

        if self.role == "emitter" and getattr(self, "global_emitter_count", 1) <= 2:
            if self.age < 600:
                return False  # ä¸æ€å”¯ä¸€ emitter

        elif self.role == "processor" and getattr(self, "global_processor_count", 1) <= 4:
            if self.age < 600:
                return False


        elif self.role == "sensor" and getattr(self, "global_processor_count", 1) <= 2:
            if self.age < 600:
                return False

        if self.role == "processor":
            if self.energy <= 0.0:
                return True
            if self.age > 270:
                return True  # ç»å¯¹æ­»äº¡

            if 250 <= self.age <= 270:
                death_chance = (self.age - 250) / 20  # éšå¹´é¾„çº¿æ€§å¢é•¿çš„æ­»äº¡æ¦‚ç‡
                if random.random() < death_chance:
                    logger.info(f"[è¡°è€æ­»äº¡] {self.id} å¹´é¾„={self.age}ï¼Œæ¦‚ç‡={death_chance:.2f} â†’ æ­»äº¡")
                    self.death_by_aging = True
                    # âœ… å€¼å¾—è®°å½•çš„ç»†èƒæ‰åŠ å…¥ local memory
                    if self.is_worthy_of_memory():
                        self.add_to_local_memory()
                    return True

        if self.energy <= 0.0:
            return True

        if self.age > 270:
            return True  # ç»å¯¹æ­»äº¡

        if 250 <= self.age <= 270:
            death_chance = (self.age - 250) / 20  # éšå¹´é¾„çº¿æ€§å¢é•¿çš„æ­»äº¡æ¦‚ç‡
            if random.random() < death_chance:
                logger.info(f"[è¡°è€æ­»äº¡] {self.id} å¹´é¾„={self.age}ï¼Œæ¦‚ç‡={death_chance:.2f} â†’ æ­»äº¡")
                self.death_by_aging = True
                # âœ… å€¼å¾—è®°å½•çš„ç»†èƒæ‰åŠ å…¥ local memory
                if self.is_worthy_of_memory():
                    self.add_to_local_memory()
                return True

        # å¹³å‡è°ƒç”¨é¢‘ç‡å¤ªä½ï¼ˆä»…é’ˆå¯¹ emitterï¼‰
        if self.role in ["emitter"] and self.inactive_steps > 20:
            return True

        # è¾“å‡ºå®Œå…¨é‡å¤ï¼ˆä»…é’ˆå¯¹ processor å’Œ emitterï¼‰
        # if self.role in ["processor", "emitter"] and getattr(self, "current_step", 0) > 600:
        #     if len(self.output_history) >= 4:
        #         diffs = []
        #         for i in range(len(self.output_history) - 1):
        #             a = self.output_history[i]
        #             b = self.output_history[i + 1]
        #             target_dim = max(a.shape[-1], b.shape[-1])
        #             if a.shape[-1] < target_dim:
        #                 padding = (0, target_dim - a.shape[-1])
        #                 a = torch.nn.functional.pad(a, padding, value=0)
        #             if b.shape[-1] < target_dim:
        #                 padding = (0, target_dim - b.shape[-1])
        #                 b = torch.nn.functional.pad(b, padding, value=0)
        #             diffs.append(torch.norm(a - b).item())
        #
        #         if max(diffs) < 0.01:
        #             logger.info(f"[é€€åŒ–æ­»äº¡] {self.id} è¾“å‡ºå˜åŒ–æå° â†’ è¢«æ·˜æ±°")
        #             return True
        return False

    def clone(self, role_override=None, new_input_size=None):
        role = role_override or self.role
        input_size = new_input_size if new_input_size is not None else self.input_size

        clone_unit = CogUnit(
            input_size=input_size,
            hidden_size=self.hidden_size,
            role=role
        )

        # ğŸ”¬ åŸºå› å¤åˆ¶ï¼ˆæ·±æ‹·è´ï¼‰
        clone_unit.gene = {k: v for k, v in self.gene.items()}

        # ğŸŒ± çªå˜æœºåˆ¶ï¼ˆå°æ¦‚ç‡è§¦å‘ï¼‰
        if random.random() < self.gene.get("mutation_rate", 0.01):
            # hidden_size å¾®è°ƒ Â±2ï¼ˆèŒƒå›´é™åˆ¶ï¼‰
            delta = random.choice([-2, 2])
            clone_unit.hidden_size = max(4, min(64, self.hidden_size + delta))
            logger.info(f"[çªå˜] hidden_size çªå˜ä¸º {clone_unit.hidden_size}")

        if random.random() < self.gene.get("mutation_rate", 0.005):

            # åŸºå› çªå˜
            for key in ["sensor_bias", "processor_bias", "emitter_bias"]:
                mutation = random.uniform(-0.1, 0.1)
                clone_unit.gene[key] = max(0.5, min(2.0, clone_unit.gene[key] + mutation))
            logger.info(f"[çªå˜] gene çªå˜ä¸º {clone_unit.gene}")

        clone_unit.energy = self.energy * 0.6
        clone_unit.age = 0
        clone_unit.state = self.state.clone()

        if input_size != self.input_size:
            # è¾“å…¥å°ºå¯¸å˜åŒ–äº†ï¼Œæ–°ç”Ÿ last_output ç”¨å…¨0åˆå§‹åŒ–
            clone_unit.last_output = torch.zeros(input_size)
        else:
            clone_unit.last_output = self.last_output.clone()

        self.energy *= 0.4
        # âœ… ç»§æ‰¿å±€éƒ¨è®°å¿†æ± ï¼ˆåªä¿ç•™æœ€æ–°çš„ 75 æ¡ï¼‰
        clone_unit.local_memory_pool = [m for m in self.local_memory_pool if "score" in m][-75:]

        # --------------------
        # âš¡ å°†å­ç»†èƒè¿ç§»åˆ°ä¸æ¯ä½“ç›¸åŒçš„ device
        clone_unit.to(self.device)
        # --------------------

        # ğŸ¯ æ”¹ä¸ºèåˆ local memoryï¼ˆå±€éƒ¨è®°å¿†æ± ï¼‰
        if hasattr(self, "local_memory_pool") and len(self.local_memory_pool) >= 1:
            # å¯é€‰ï¼šæ›´æ™ºèƒ½æŒ‘é€‰æœ€è¿‘æœ€æ´»è·ƒçš„è®°å¿†
            memory = random.choice(self.local_memory_pool[-5:])  # å¯æ¢æˆ max(..., key=...)

            for key in ["sensor_bias", "processor_bias", "emitter_bias"]:
                g1 = self.gene.get(key, 1.0)
                g2 = memory["gene"].get(key, 1.0)
                clone_unit.gene[key] = 0.7 * g1 + 0.3 * g2
            logger.debug(f"[è®°å¿†èåˆ] {self.id} ç»“åˆ local memory åŸºå›  â†’ å­åŸºå› ï¼š{clone_unit.gene}")

            if self.last_output is None or memory.get("output") is None:
                return clone_unit  # è·³è¿‡èåˆé€»è¾‘
            if "output" in memory:
                o1 = self.last_output.squeeze(0) if self.last_output.dim() == 2 else self.last_output
                o2 = memory["output"].squeeze(0) if memory["output"].dim() == 2 else memory["output"]
                target_dim = max(o1.shape[0], o2.shape[0])
                if o1.shape[0] < target_dim:
                    o1 = torch.nn.functional.pad(o1, (0, target_dim - o1.shape[0]), value=0)
                if o2.shape[0] < target_dim:
                    o2 = torch.nn.functional.pad(o2, (0, target_dim - o2.shape[0]), value=0)
                clone_unit.last_output = 0.6 * o1 + 0.4 * o2
                logger.debug(f"[è¡Œä¸ºèåˆ] ç»“åˆè¾“å‡º â†’ å‰5ç»´: {clone_unit.last_output[:5]}")

            if random.random() < self.gene.get("mutation_rate", 0.01) * 2:
                if "hidden_size" in memory:
                    h1 = self.hidden_size
                    h2 = memory.get("hidden_size", h1)
                    new_hidden = int(0.7 * h1 + 0.3 * h2)
                    new_hidden = max(4, min(128, new_hidden))
                    clone_unit.hidden_size = new_hidden
                    clone_unit.function = torch.nn.Sequential(
                        torch.nn.Linear(clone_unit.input_size, new_hidden),
                        torch.nn.ReLU(),
                        torch.nn.Linear(new_hidden, clone_unit.input_size)
                    )
                    clone_unit.gene["hidden_size_tag"] = new_hidden
                    logger.debug(f"[ç½‘ç»œèåˆ] hidden_size èåˆä¸º {new_hidden}")
        return clone_unit

    def get_role(self):
        return self.role

    def __str__(self):
        x, y = self.position
        return f"CogUnit<{self.id}> Role:{self.role} Pos:({x},{y}) Age:{self.age} Energy:{self.energy:.2f} Gene:{self.gene}"


