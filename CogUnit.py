# cogunit.py
import torch
import uuid
import random

# === Split-Gate åŠ¨æ€é˜ˆå€¼è¡¨ï¼ˆè¿‡é‡ä¸Šé™ï¼‰===========================
# æ¯”ä¾‹ k_esï¼šEmitter <-> Sensor   ï¼  k_pï¼š ç›¸å¯¹ Processor/2
SPLIT_HI_ES_TABLE = { 50: 1.40, 200: 1.25, 500: 1.15, float("inf"): 1.08 }
SPLIT_HI_P_TABLE  = { 50: 1.25, 200: 1.15, 500: 1.10, float("inf"): 1.05 }

TOL_FRAC_SPLIT = 0.05      # è‡³å°‘å·®å€¼ Î”â‰¥ceil(totalÃ—5 %) ï¼ˆä¸” â‰¥1ï¼‰
# ===============================================================

def _get_hi(table, total):
    """æŒ‰ç…§æ€»ç»†èƒæ•°è¿”å›å½“å‰é˜¶æ®µçš„ hi é˜ˆå€¼"""
    for lim, val in table.items():
        if total < lim:
            return val
    return table[float("inf")]



# â”€â”€ è§’è‰²åˆ†è£‚æœ€ä½èƒ½é‡é˜ˆå€¼ ä»¥åŠ æœ€ä½è°ƒç”¨é¢‘ç‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROLE_SPLIT_RULE = {
    "sensor":    {"min_e": 1.2, "min_calls": 0},   # è½»é‡ï¼Œå‡ ä¹ä¸é™åˆ¶è°ƒç”¨é¢‘ç‡
    "processor": {"min_e": 1.6, "min_calls": 1},   # ä¸­ç­‰
    "emitter":   {"min_e": 2.2, "min_calls": 2},   # æœ€é‡ï¼Œé—¨æ§›æœ€é«˜
}
# ----------------------------------------------------



class CogUnit:
    """
    CogUnit æ˜¯ EvoCore çš„æœ€å°è®¤çŸ¥å•å…ƒï¼š
    - æ‹¥æœ‰ç‹¬ç«‹çŠ¶æ€ã€èƒ½é‡ã€å¹´é¾„
    - å¯è¿›è¡ŒçŠ¶æ€æ›´æ–°ï¼ˆupdateï¼‰ä¸è¾“å‡º
    - å¯åˆ¤æ–­æ˜¯å¦åˆ†è£‚ï¼ˆshould_splitï¼‰ä¸æ­»äº¡ï¼ˆshould_dieï¼‰
    - å¯å…‹éš†ç”Ÿæˆæ–°å•å…ƒï¼ˆcloneï¼‰
    """

    def __init__(self, input_size=50, hidden_size=16, role="processor"):
        # åŸºå› è¡¨è¾¾ï¼Œè¡¨ç¤ºå¯¹ä¸åŒåŠŸèƒ½çš„åå¥½
        self.gene = {
            "sensor_bias": random.uniform(0.8, 1.2),
            "processor_bias": random.uniform(0.8, 1.2),
            "emitter_bias": random.uniform(0.8, 1.2),
            "mutation_rate": 0.01  # æ¯æ¬¡å¤åˆ¶æœ‰1%æ¦‚ç‡çªå˜
        }

        self.subsystem_id = None  # åˆå§‹æ²¡æœ‰å­ç³»ç»Ÿå½’å±
        self.output_history = []  # âœ… ç”¨äºè®°å½•è¿‘å‡ æ¬¡è¾“å‡ºï¼Œè¯„ä¼°æ˜¯å¦è¡Œä¸ºå•ä¸€
        self.call_history = []  # è®°å½•æœ€è¿‘å‡ æ­¥çš„è°ƒç”¨æ¬¡æ•°
        self.call_window = 5  # çª—å£é•¿åº¦ï¼Œè¿‡å» 5 æ­¥
        self.inactive_steps = 0
        self.position = (random.randint(0, 10), random.randint(0, 10))  # å¯è°ƒèŒƒå›´
        self.state_memory = []  # è®°å¿†é˜Ÿåˆ—
        self.memory_limit = 5  # å¯è°ƒæ•´ä¸º k æ­¥
        self.role = role
        self.id = uuid.uuid4()          # å”¯ä¸€æ ‡è¯†
        self.energy = 1.0               # åˆå§‹èƒ½é‡
        self.age = 0                    # ç”Ÿå­˜æ­¥æ•°
        self.input_size = input_size
        self.hidden_size = hidden_size

        # è®¤çŸ¥çŠ¶æ€å‘é‡
        self.state = torch.zeros(hidden_size)

        # å¾®å‹å‰é¦ˆç½‘ç»œï¼ˆè¾“å…¥ç»´åº¦ â†’ éšè—ç»´åº¦ â†’ å›åˆ°è¾“å…¥ç»´åº¦ï¼‰
        self.function = torch.nn.Sequential(
            torch.nn.Linear(input_size, hidden_size),
            torch.nn.ReLU(),
            torch.nn.Linear(hidden_size, input_size)
        )

        self.last_output = torch.zeros(input_size)

        if "mutation_rate" not in self.gene:
            self.gene["mutation_rate"] = 0.05

    def get_position(self):
        return self.position

    def mini_learn(self, input_tensor, target_tensor, lr=0.001):
        if input_tensor.dim() == 1:
            input_tensor = input_tensor.unsqueeze(0)
        if target_tensor.dim() == 1:
            target_tensor = target_tensor.unsqueeze(0)

        # Forward
        output = self.function(input_tensor)

        # Loss
        loss = torch.nn.functional.mse_loss(output, target_tensor)

        # Backward
        self.function.zero_grad()
        loss.backward()

        # Manual parameter update
        with torch.no_grad():
            for param in self.function.parameters():
                if param.grad is not None:
                    param.copy_(param - lr * param.grad)


        print(f"[Mini-Learn] {self.id} loss={loss.item():.4f} (lr={lr})")


    def compute_self_reward(self, input_tensor, output_tensor):
        """
        ç®€å• self-rewardï¼šå¦‚æœè¾“å‡ºèƒ½è·Ÿè¾“å…¥ä¿æŒä¸€è‡´æ€§ï¼Œå°±è·å¾—å°å¥–åŠ±
        """
        if input_tensor.shape != output_tensor.shape:
            output_tensor = output_tensor[:, :input_tensor.shape[1]]  # é˜²æ­¢ç»´åº¦ä¸åŒ
        error = torch.mean((input_tensor - output_tensor) ** 2)
        reward = 0.01 * (self.input_size / 50) * (1.0 - error.item())  # errorè¶Šå°å¥–åŠ±è¶Šé«˜
        return max(reward, 0.0)  # ä¸è®©å¥–åŠ±ä¸ºè´Ÿæ•°


    def update(self, input_tensor: torch.Tensor):
        """æ›´æ–° CogUnit çŠ¶æ€"""
        if input_tensor.dim() == 1:
            input_tensor = input_tensor.unsqueeze(0)

        # ğŸš¨ å…ˆæ£€æŸ¥ input_size æ˜¯å¦éœ€è¦æ‰©å±•ï¼ˆåŠ¨æ€é€‚é…ç¯å¢ƒå˜åŒ–ï¼‰
        current_input_size = input_tensor.shape[-1]
        if current_input_size != self.input_size:
            print(f"[åŠ¨æ€æ‰©å±•] {self.id} è¾“å…¥å°ºå¯¸å˜åŒ– {self.input_size} â†’ {current_input_size}")

            # é‡å»º function ç½‘ç»œ
            self.function = torch.nn.Sequential(
                torch.nn.Linear(current_input_size, self.hidden_size),
                torch.nn.ReLU(),
                torch.nn.Linear(self.hidden_size, current_input_size)
            )
            self.input_size = current_input_size
            self.last_output = torch.zeros(current_input_size, device=input_tensor.device)

        # === Forward: å†…éƒ¨å¤„ç† ===
        raw_output = self.function(input_tensor)  # æ­£å¸¸forward
        self.last_output = raw_output.detach().clone()  # âš¡ å…³é”®ï¼šdetachæ‰ï¼Œé¿å…æ±¡æŸ“è®¡ç®—å›¾
        self.state = self.last_output.clone()

        # âœ… å­˜å‚¨è¾“å‡ºå†å²ï¼Œä¾›è¡Œä¸ºè´¨é‡åˆ¤æ–­ç”¨
        self.output_history.append(self.last_output.detach().clone())
        if len(self.output_history) > 5:
            self.output_history.pop(0)
        self.age += 1

        # === å¤–éƒ¨çŠ¶æ€è®°å¿†ï¼ˆç”¨äºåç»­å¥–åŠ±æœºåˆ¶ï¼‰ ===
        self.state_memory.append(self.state.clone())
        if len(self.state_memory) > self.memory_limit:
            self.state_memory.pop(0)

        # ========================
        # ğŸš¨ åŠ¨æ€èƒ½é‡æ¶ˆè€—é€»è¾‘éƒ¨åˆ†
        # ========================

        # 1ï¸âƒ£ è¾“å…¥å¤æ‚åº¦ï¼šä½¿ç”¨æ–¹å·®ä½œä¸ºç†µçš„è¿‘ä¼¼
        input_var = torch.var(input_tensor).item()

        # 2ï¸âƒ£ è°ƒç”¨é¢‘ç‡ï¼šå¤–éƒ¨ç”± Graph å†™å…¥ recent_calls å±æ€§
        recent_call_freq = getattr(self, "recent_calls", 1)

        # 3ï¸âƒ£ æ´»è·ƒè¿æ¥æ•°ï¼šå¤–éƒ¨ç”± Graph å†™å…¥ connection_count å±æ€§
        connection_count = getattr(self, "connection_count", 1)

        # âš ï¸ ä»£è°¢å·²ç”± CogGraph æ§åˆ¶ï¼Œè¿™é‡Œä¸å†æ¶ˆè€— energy

        # === é«˜é¢‘è°ƒç”¨å¥–åŠ±æœºåˆ¶ ===
        avg_recent_calls = getattr(self, "avg_recent_calls", 0.0)
        if avg_recent_calls >= 2.0 and self.energy > 0.0:
            self.energy += 0.02
            print(f"[å¥–åŠ±] {self.id} å¹³å‡è°ƒç”¨é¢‘ç‡ {avg_recent_calls:.2f} â†’ èƒ½é‡ +0.02")

        # === è¾“å‡ºæ‰°åŠ¨ï¼šæ¨¡æ‹Ÿæ—©æœŸæ¢ç´¢è¡Œä¸ºï¼ˆå‰10æ­¥ï¼‰===
        if hasattr(self, "current_step"):
            if self.get_role() == "emitter" and self.current_step < 20:
                noise = torch.randn_like(self.last_output) * 0.2
                self.last_output += noise
                print(f"[æ‰°åŠ¨] emitter {self.id} è¾“å‡ºåŠ å…¥æ‰°åŠ¨")
            elif self.get_role() == "processor" and self.current_step < 5:
                noise = torch.randn_like(self.last_output) * 0.1
                self.last_output += noise
                print(f"[æ‰°åŠ¨] processor {self.id} è¾“å‡ºåŠ å…¥æ‰°åŠ¨")

        # === âœ… å†…éƒ¨å¥–åŠ±æœºåˆ¶ Self-Reward ===
        self_reward = self.compute_self_reward(input_tensor, self.last_output)
        self.energy += self_reward
        if self_reward > 0:
            print(f"[å†…éƒ¨å¥–åŠ±] {self.id} è‡ªè¯„å¥–åŠ± +{self_reward:.4f} èƒ½é‡ (ç°æœ‰èƒ½é‡ {self.energy:.2f})")

        # === âœ… å±€éƒ¨å¾®å‹å­¦ä¹ 
        if self.get_role() == "emitter":
            bias = self.gene.get("emitter_bias", 1.0)
            lr = 0.001 * (2.0 - min(1.5, bias))
            self.mini_learn(input_tensor, self.last_output.detach(), lr=lr)

        else:
            # processor/sensor ä»æ˜¯è‡ªç¼–ç å¼
            bias = self.gene.get("processor_bias", 1.0) if self.role == "processor" else self.gene.get("sensor_bias",
                                                                                                       1.0)
            lr = 0.001 * (2.0 - min(1.5, bias))  # bias è¶Šé«˜ï¼Œå­¦ä¹ ç‡è¶Šä½ï¼Œä»£è¡¨æ›´â€œç¨³å¥â€ï¼Œè¶Šä½åˆ™æ›´æ˜“æ¿€åŠ¨
            self.mini_learn(input_tensor, input_tensor, lr=lr)

    def get_output(self) -> torch.Tensor:
        """è¿”å›ç»™ä¸‹æ¸¸å•å…ƒä½¿ç”¨çš„è¾“å‡º (shape=[1, input_size])"""
        return self.last_output

    def should_split(self):


        emitter_count = getattr(self, "global_emitter_count", 1)
        processor_count = getattr(self, "global_processor_count", 1)
        sensor_count = getattr(self, "global_sensor_count", 1)
        total = getattr(self, "global_unit_count", 1)

        role = self.get_role()

        # âœ… å„ç±»ç»†èƒç´§æ€¥å¢æ®–
        if role == "emitter" and emitter_count <= 1:
            print(f"[ç´§æ€¥å¢æ®–] {self.id} æ˜¯å”¯ä¸€ emitterï¼Œå¼ºåˆ¶å°è¯•åˆ†è£‚å¹¶è¡¥ç»™")
            self.energy += 1.5  # ğŸ’¡ è¡¥ç»™èƒ½é‡
            return True

        if role == "processor" and processor_count <= 1:
            print(f"[ç´§æ€¥å¢æ®–] {self.id} æ˜¯å”¯ä¸€ processorï¼Œå¼ºåˆ¶å°è¯•åˆ†è£‚å¹¶è¡¥ç»™")
            self.energy += 1.5
            return True

        if role == "sensor" and sensor_count <= 1:
            print(f"[ç´§æ€¥å¢æ®–] {self.id} æ˜¯å”¯ä¸€ sensorï¼Œå¼ºåˆ¶å°è¯•åˆ†è£‚å¹¶è¡¥ç»™")
            self.energy += 1.5
            return True

        # ===ã€Split-Gate : 1 : 2 : 1 åŠ¨æ€é—¨æ§›ã€‘===========================
        total = getattr(self, "global_unit_count", sensor_count + processor_count + emitter_count)

        hi_es = _get_hi(SPLIT_HI_ES_TABLE, total)  # emitter <-> sensor
        hi_p = _get_hi(SPLIT_HI_P_TABLE, total)  # ç›¸å¯¹ processor/2
        half_p = processor_count / 2

        # å·®å€¼å¿…é¡» â‰¥1 ä¸” â‰¥ceil(totalÃ—TOL) æ‰ç®—â€œçœŸçš„å¤šâ€
        def _delta_enough(x, y):
            delta = x - y
            return delta >= max(1, int(total * TOL_FRAC_SPLIT))

        overpop = False
        if role == "emitter":
            if (_delta_enough(emitter_count, sensor_count * hi_es) or
                    _delta_enough(emitter_count, half_p * hi_p)):
                overpop = True
        elif role == "sensor":
            if (_delta_enough(sensor_count, emitter_count * hi_es) or
                    _delta_enough(sensor_count, half_p * hi_p)):
                overpop = True
        elif role == "processor":
            # processor è¶…æ ‡ï¼šå…¶ä¸€åŠç›¸å¯¹ e/s ä¹Ÿè¶…æ ‡
            if (_delta_enough(half_p, emitter_count * hi_p) or
                    _delta_enough(half_p, sensor_count * hi_p)):
                overpop = True

        if overpop:
            return False
        # ================================================================

        # è§’è‰²ä¸“å±èƒ½é‡ + è°ƒç”¨é—¨æ§› ----------------------
        rule = ROLE_SPLIT_RULE[role]
        if self.energy < rule["min_e"]:
            return False
        if role != "sensor" and self.avg_recent_calls < rule["min_calls"]:
            return False

        if len(self.output_history) >= 3:
            recent = self.output_history[-3:]
            if all(torch.equal(recent[0], o) for o in recent[1:]):
                return False

        return True

    def should_die(self) -> bool:

        if self.role == "emitter" and getattr(self, "global_emitter_count", 1) <= 2:
            if self.age < 600:
                return False  # ä¸æ€å”¯ä¸€ emitter

        elif self.role == "processor" and getattr(self, "global_processor_count", 1) <= 4:
            if self.age < 600:
                return False


        elif self.role == "sensor" and getattr(self, "global_processor_count", 1) <= 2:
            if self.age < 600:
                return False

        # ğŸ§  æ™ºèƒ½å¯¿å‘½æœºåˆ¶ï¼šå¹´è€ä¸”ä¸æ´»è·ƒå°±æ­»

        if self.energy <= 0.0 or self.age > 300:
            return True
        # å¹³å‡è°ƒç”¨é¢‘ç‡å¤ªä½ï¼ˆä»…é’ˆå¯¹ processor å’Œ emitterï¼‰
        if self.role in ["processor", "emitter"] and self.inactive_steps > 20:
            return True

        # è¾“å‡ºå®Œå…¨é‡å¤ï¼ˆä»…é’ˆå¯¹ processor å’Œ emitterï¼‰
        if self.role in ["processor", "emitter"] and getattr(self, "current_step", 0) > 600:
            if len(self.output_history) >= 4:
                diffs = []
                for i in range(len(self.output_history) - 1):
                    a = self.output_history[i]
                    b = self.output_history[i + 1]
                    target_dim = max(a.shape[-1], b.shape[-1])
                    if a.shape[-1] < target_dim:
                        padding = (0, target_dim - a.shape[-1])
                        a = torch.nn.functional.pad(a, padding, value=0)
                    if b.shape[-1] < target_dim:
                        padding = (0, target_dim - b.shape[-1])
                        b = torch.nn.functional.pad(b, padding, value=0)
                    diffs.append(torch.norm(a - b).item())

                if max(diffs) < 0.01:
                    print(f"[é€€åŒ–æ­»äº¡] {self.id} è¾“å‡ºå˜åŒ–æå° â†’ è¢«æ·˜æ±°")
                    return True
        return False

    def clone(self, role_override=None, new_input_size=None):
        role = role_override or self.role
        input_size = new_input_size if new_input_size is not None else self.input_size

        clone_unit = CogUnit(
            input_size=input_size,
            hidden_size=self.hidden_size,
            role=role
        )
        # ğŸ”¬ åŸºå› å¤åˆ¶ï¼ˆæ·±æ‹·è´ï¼‰
        clone_unit.gene = {k: v for k, v in self.gene.items()}

        # ğŸŒ± çªå˜æœºåˆ¶ï¼ˆå°æ¦‚ç‡è§¦å‘ï¼‰
        if random.random() < self.gene.get("mutation_rate", 0.05):

            # role çªå˜ï¼ˆé¿å… sensor â†’ emitter å¤ªçªå…€ï¼‰
            if self.role == "stem":
                role = "stem"  # ä¿æŒ stemï¼Œä¸å…è®¸çªå˜
            else:
                possible_roles = ["sensor", "processor", "emitter"]
                possible_roles.remove(self.role)
                clone_unit.role = random.choice(possible_roles)
            print(f"[çªå˜] è§’è‰²çªå˜ {self.role} â†’ {clone_unit.role}")

        if random.random() < self.gene.get("mutation_rate", 0.05):
            # hidden_size å¾®è°ƒ Â±2ï¼ˆèŒƒå›´é™åˆ¶ï¼‰
            delta = random.choice([-2, 2])
            clone_unit.hidden_size = max(4, min(64, self.hidden_size + delta))
            print(f"[çªå˜] hidden_size çªå˜ä¸º {clone_unit.hidden_size}")

        if random.random() < self.gene.get("mutation_rate", 0.05):

            # åŸºå› çªå˜
            for key in ["sensor_bias", "processor_bias", "emitter_bias"]:
                mutation = random.uniform(-0.1, 0.1)
                clone_unit.gene[key] = max(0.5, min(2.0, clone_unit.gene[key] + mutation))
            print(f"[çªå˜] gene çªå˜ä¸º {clone_unit.gene}")

        clone_unit.energy = self.energy * 0.6
        clone_unit.age = 0
        clone_unit.state = self.state.clone()

        if input_size != self.input_size:
            # è¾“å…¥å°ºå¯¸å˜åŒ–äº†ï¼Œæ–°ç”Ÿ last_output ç”¨å…¨0åˆå§‹åŒ–
            clone_unit.last_output = torch.zeros(input_size)
        else:
            clone_unit.last_output = self.last_output.clone()

        self.energy *= 0.4

        # ğŸ¯ èåˆæœ€è¿‘æ­»äº¡å•å…ƒçš„é—äº§ï¼ˆç§æ—è®°å¿†ï¼‰
        if hasattr(self, "memory_pool") and len(self.memory_pool) >= 3:
            memory = random.choice(self.memory_pool[-5:])  # å–æœ€è¿‘5æ¡é—äº§ä¹‹ä¸€
            for key in ["sensor_bias", "processor_bias", "emitter_bias"]:
                g1 = self.gene.get(key, 1.0)
                g2 = memory["gene"].get(key, 1.0)
                clone_unit.gene[key] = 0.7 * g1 + 0.3 * g2  # èåˆé—ä¼ 
            print(f"[é—ä¼ èåˆ] {self.id} ç»“åˆè®°å¿†æ± åŸºå›  â†’ å­åŸºå› ï¼š{clone_unit.gene}")

            if "output" in memory:
                o1 = self.last_output.squeeze(0) if self.last_output.dim() == 2 else self.last_output
                o2 = memory["output"].squeeze(0) if memory["output"].dim() == 2 else memory["output"]

                target_dim = max(o1.shape[0], o2.shape[0])
                if o1.shape[0] < target_dim:
                    o1 = torch.nn.functional.pad(o1, (0, target_dim - o1.shape[0]), value=0)
                if o2.shape[0] < target_dim:
                    o2 = torch.nn.functional.pad(o2, (0, target_dim - o2.shape[0]), value=0)

                clone_unit.last_output = 0.6 * o1 + 0.4 * o2
                print(f"[è¡Œä¸ºé—ä¼ ] èåˆè¡Œä¸ºæ¨¡æ¿ â†’ output å‰5ç»´: {clone_unit.last_output[:5]}")

            if random.random() < self.gene["mutation_rate"] * 2:
                if "hidden_size" in memory:
                    h1 = self.hidden_size
                    h2 = memory.get("hidden_size", h1)
                    new_hidden = int(0.7 * h1 + 0.3 * h2)
                    new_hidden = max(4, min(128, new_hidden))
                    clone_unit.hidden_size = new_hidden
                    print(f"[éšå±‚é—ä¼ ] hidden_size ç»§æ‰¿ä¸º {new_hidden}")
                    # é‡æ–°æ„å»ºç½‘ç»œ
                    clone_unit.function = torch.nn.Sequential(
                        torch.nn.Linear(clone_unit.input_size, new_hidden),
                        torch.nn.ReLU(),
                        torch.nn.Linear(new_hidden, clone_unit.input_size)
                    )

        print(f"[åˆ†è£‚] {self.id} â†’ {clone_unit.id} (input_size={input_size}, çˆ¶èƒ½é‡ç•™40%ï¼Œå­èƒ½é‡å¾—60%ï¼Œè§’è‰²: {role})")
        return clone_unit

    def get_role(self):
        return self.role

    def __str__(self):
        x, y = self.position
        return f"CogUnit<{self.id}> Role:{self.role} Pos:({x},{y}) Age:{self.age} Energy:{self.energy:.2f} Gene:{self.gene}"


